#!/usr/bin/env python3
"""
CourtRankRL CLI Interface
Agents.md specifikÃ¡ciÃ³ alapjÃ¡n implementÃ¡lva.

Parancsok:
- build: Docling feldolgozÃ¡s â†’ chunking â†’ BM25 index
- query: hibrid (BM25+FAISS) keresÃ©s, opcionÃ¡lis GRPO reranking
- train: GRPO reranker policy tanÃ­tÃ¡sa (baseline â†’ feature export â†’ GRPO)
"""

import argparse
import sys
from pathlib import Path
from typing import List

project_root = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(project_root))

from configs import config
from src.data_loader.preprocess_documents import main as build_docs
from src.data_loader.build_bm25_index import main as build_bm25
from src.data_loader.export_training_slates import main as export_slates
from src.search.hybrid_search import HybridRetriever
from src.search.grpo_reranker import GRPOReranker

def build_command():
    """Build pipeline: Docling â†’ chunking â†’ BM25."""
    print("=== COURTRANKRL BUILD PIPELINE ===")

    try:
        # Step 1: Ingestion with Docling
        print("ğŸ“„ Step 1: Docling ingestion and normalization...")
        print("   (DOCX parsing, minimal normalization)")
        build_docs()

        # Step 2: Chunking
        print("âœ‚ï¸  Step 2: Intelligent chunking...")
        print("   (Docling decides chunk size and overlap)")

        # Step 3: BM25 indexing
        print("ğŸ” Step 3: BM25S index (bm25s.tokenize + cache)...")
        build_bm25()

        print("\nâœ… BUILD PIPELINE COMPLETE!")
        print("ğŸ“Š Generated artifacts:")
        print(f"   ğŸ“„ Chunks: {config.CHUNKS_JSONL}")
        print(f"   ğŸ” BM25 Index: {config.BM25_INDEX_PATH}")

        print("\nğŸš€ Ready for queries! Use: uv run courtrankrl query \"your question\"")
        print("ğŸ“ Note: FAISS index and embeddings should be generated using gemma_embedding_runpod.ipynb")

    except Exception as e:
        print(f"\nâŒ BUILD FAILED: {e}")
        print("ğŸ’¡ Check the error message above and try again.")
        sys.exit(1)

def export_slate_command():
    """Export training slates for GRPO cloud training."""
    print("=== COURTRANKRL SLATE EXPORT ===")
    print("ğŸ¯ Training slates exportÃ¡lÃ¡sa GRPO cloud traininghez")
    print("ğŸ“ Kimenet: data/models/grpo_policy/training_slates.jsonl")

    try:
        export_slates()
        print("\nâœ… SLATE EXPORT KÃ‰SZ!")
        print("ğŸ“Š ExportÃ¡lt fÃ¡jlok:")
        print(f"   ğŸ“„ Training slates: {config.GRPO_SLATE_EXPORT_PATH}")
        print("\nğŸš€ KÃ©szen a cloud trainingre!")
        print("ğŸ’¡ Futtasd: notebooks/grpo_train_runpod.ipynb a Runpod-on")

    except Exception as e:
        print(f"\nâŒ SLATE EXPORT FAILED: {e}")
        print("ğŸ’¡ GyÅ‘zÅ‘dj meg rÃ³la, hogy a qrels Ã©s chunks fÃ¡jlok lÃ©teznek.")
        sys.exit(1)

def query_command(query: str, top_k: int = 10, rerank: bool = True):
    """Query pipeline: embed query â†’ BM25 + dense â†’ fusion â†’ RL reranking â†’ doc IDs."""
    print("=== COURTRANKRL QUERY PIPELINE ===")
    print(f"ğŸ” LekÃ©rdezÃ©s: {query}")
    print(f"ğŸ“Š Top-K: {top_k}")
    print(f"ğŸ§  Reranking: {'bekapcsolva' if rerank else 'kikapcsolva'}")

    try:
        # Initialize retriever
        retriever = HybridRetriever()

        if rerank:
            # Step 1: Get candidates for reranking (agents.md step 4)
            print("ğŸ“‹ Step 1: Retrieving candidates for reranking...")
            retriever.retrieve_candidates(query, top_k=config.TOP_K_BASELINE)
            bm25_results = retriever.get_last_doc_scores("bm25")
            dense_results = retriever.get_last_doc_scores("dense")

            print(f"   ğŸ“„ BM25 jelÃ¶ltek: {len(bm25_results)}")
            print(f"   ğŸ§  Dense jelÃ¶ltek: {len(dense_results)}")

            # Step 2: Apply GRPO reranking (agents.md step 5)
            print("ğŸ¯ Step 2: Applying GRPO reranking...")
            try:
                reranker = GRPOReranker()
                # Load chunks data for context
                chunks_data = {}
                if config.CHUNKS_JSONL.exists():
                    import json
                    with open(config.CHUNKS_JSONL, 'r', encoding='utf-8') as f:
                        for line in f:
                            chunk = json.loads(line.strip())
                            chunks_data[chunk['chunk_id']] = chunk

                reranked = reranker.rerank(retriever, bm25_results, dense_results, query, chunks_data)[:top_k]
                print(f"   âœ… Ãšjrendezett lista: {len(reranked)} dokumentum")

                print("\nğŸ¯ RERANKELT EREDMÃ‰NYEK:")
                for idx, (doc_id, score) in enumerate(reranked, start=1):
                    print(f"{idx}. {doc_id} (GRPO pont: {score:.4f})")

            except Exception as e:
                print(f"âš ï¸  GRPO reranker unavailable ({e}), falling back to baseline...")
                rerank = False

        if not rerank:
            # Step 1: Hybrid baseline retrieval (agents.md step 4)
            print("ğŸ“‹ Step 1: Hybrid baseline retrieval...")
            doc_ids = retriever.retrieve(query, top_k=top_k, fusion_method="rrf")

            print(f"   ğŸ“„ TalÃ¡latok szÃ¡ma: {len(doc_ids)}")

            print("\nğŸ” BASELINE EREDMÃ‰NYEK:")
            for idx, doc_id in enumerate(doc_ids, start=1):
                print(f"{idx}. {doc_id}")

        print(f"\nâœ… Query completed successfully!")

    except Exception as e:
        print(f"\nâŒ QUERY FAILED: {e}")
        print("ğŸ’¡ Make sure indexes are built: uv run courtrankrl build")
        sys.exit(1)

def train_command():
    """Train GRPO reranker using cloud notebook."""
    print("=== COURTRANKRL GRPO TRAINING PIPELINE ===")
    print("Agents.md spec: 5) RL Reranking (GRPO-style)")
    print("ğŸ¯ CÃ©l: a baseline javÃ­tÃ¡sa megerÅ‘sÃ­tÃ©ses tanulÃ¡ssal")
    print("â˜ï¸  Training a cloud GPU-n (Runpod) keresztÃ¼l")

    try:
        # Check prerequisites
        if not config.BASELINE_QRELS_FILE.exists():
            print(f"âŒ Qrels fÃ¡jl nem talÃ¡lhatÃ³: {config.BASELINE_QRELS_FILE}")
            print("ğŸ’¡ Hozz lÃ©tre qrels fÃ¡jlt: data/qrels/baseline_qrels.tsv")
            sys.exit(1)

        if not config.CHUNKS_JSONL.exists():
            print(f"âŒ Chunks fÃ¡jl nem talÃ¡lhatÃ³: {config.CHUNKS_JSONL}")
            print("ğŸ’¡ Futtasd elÅ‘bb: uv run courtrankrl build")
            sys.exit(1)

        print("ğŸ“‹ Prerequisites check: âœ…")
        print("ğŸ“š TanÃ­tÃ³ adatok elÅ‘kÃ©szÃ­tÃ©se...")

        # Export training slates
        export_slates()

        print("\nâœ… TRAINING DATA ELÅKÃ‰SZÃTVE!")
        print("ğŸ“Š ExportÃ¡lt fÃ¡jlok:")
        print(f"   ğŸ“„ Training slates: {config.GRPO_SLATE_EXPORT_PATH}")

        print("\nğŸš€ KÃ–VETKEZÅ LÃ‰PÃ‰SEK:")
        print("1. MÃ¡sold Ã¡t a training slates fÃ¡jlt a Runpod workspace-be")
        print("2. Futtasd a notebook-ot: notebooks/grpo_train_runpod.ipynb")
        print("3. MÃ¡sold vissza az artifacts kÃ¶nyvtÃ¡rat: data/models/grpo_policy/")
        print("4. Teszteld a query parancsot --rerank opciÃ³val")

        print("\nğŸ’¡ Runpod workflow:")
        print("   - Environment variables: HF_TOKEN beÃ¡llÃ­tva")
        print("   - Mixed precision: bf16 engedÃ©lyezve")
        print("   - Artifacts sync: /workspace/artifacts/grpo_policy/ â†’ local data/models/grpo_policy/")

    except Exception as e:
        print(f"\nâŒ GRPO TRAINING PREP FAILED: {e}")
        print("ğŸ’¡ Check prerequisites and try again.")
        sys.exit(1)

def main():
    """Main CLI entry point for CourtRankRL."""
    parser = argparse.ArgumentParser(
        description="CourtRankRL - Magyar bÃ­rÃ³sÃ¡gi dÃ¶ntÃ©sek retrieval rendszer",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
PÃ©ldÃ¡k hasznÃ¡latra:

  # Build pipeline futtatÃ¡sa
  uv run courtrankrl build

  # KeresÃ©s baseline mÃ³dban
  uv run courtrankrl query "csalÃ¡di jogi Ã¼gy" --no-rerank

  # KeresÃ©s GRPO reranking-gal
  uv run courtrankrl query "szerzÅ‘dÃ©ses jog" --top-k 5

  # Training slates exportÃ¡lÃ¡sa
  uv run courtrankrl export-slate

  # GRPO cloud training elÅ‘kÃ©szÃ­tÃ©se
  uv run courtrankrl train

HasznÃ¡lat elÅ‘tt:
  1. uv run courtrankrl build
  2. Generate FAISS index using gemma_embedding_runpod.ipynb
  3. Export training slates: uv run courtrankrl export-slate
  4. Cloud GRPO training: notebooks/grpo_train_runpod.ipynb
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='ElÃ©rhetÅ‘ parancsok')

    # Build command
    build_parser = subparsers.add_parser(
        'build',
        help='Build pipeline: Docling â†’ chunking â†’ BM25 indexing'
    )

    # Query command
    query_parser = subparsers.add_parser(
        'query',
        help='KeresÃ©s a rendszerben dokumentum azonosÃ­tÃ³kkal'
    )
    query_parser.add_argument(
        'query',
        help='KeresÃ©si lekÃ©rdezÃ©s'
    )
    query_parser.add_argument(
        '--top-k', type=int, default=10,
        help='VisszaadandÃ³ dokumentumok szÃ¡ma (alap: 10)'
    )
    query_parser.add_argument(
        '--fusion-method', choices=['rrf', 'zscore'], default='rrf',
        help='Fusion method: rrf vagy zscore (alap: rrf)'
    )
    query_parser.add_argument(
        '--no-rerank', action='store_true',
        help='GRPO reranking kikapcsolÃ¡sa (csak baseline keresÃ©s)'
    )

    # Export slate command
    export_slate_parser = subparsers.add_parser(
        'export-slate',
        help='Training slates exportÃ¡lÃ¡sa GRPO cloud traininghez'
    )

    # Train command
    train_parser = subparsers.add_parser(
        'train',
        help='GRPO reranker cloud training elÅ‘kÃ©szÃ­tÃ©se'
    )

    # Parse arguments
    args = parser.parse_args()

    # Route to appropriate command
    if args.command == 'build':
        build_command()
    elif args.command == 'query':
        query_command(args.query, args.top_k, not args.no_rerank)
    elif args.command == 'export-slate':
        export_slate_command()
    elif args.command == 'train':
        train_command()
    else:
        parser.print_help()
        print("\nğŸ’¡ KezdÃ©shez: uv run courtrankrl build")

if __name__ == '__main__':
    main()
