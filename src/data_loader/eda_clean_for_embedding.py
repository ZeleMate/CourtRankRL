# Ez a szkript felel≈ës a `preprocess_documents.py` √°ltal gener√°lt nyers CSV
# f√°jl(ok) beolvas√°s√°√©rt, a sz√∂veges adatok tiszt√≠t√°s√°√©rt, sz≈±r√©s√©√©rt,
# √©s a v√©gs≈ë, embedding k√©sz√≠t√©sre el≈ëk√©sz√≠tett CSV f√°jl ment√©s√©√©rt.
import pandas as pd
import sys
from pathlib import Path
import re
from tqdm import tqdm
import csv
import logging
import os

# --- PATH KONFIGUR√ÅCI√ì ---
# Projekt gy√∂k√©rk√∂nyvt√°r√°nak hozz√°ad√°sa a Python √∫tvonalhoz
project_root = Path(__file__).resolve().parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

try:
    from configs import config
except ImportError as e:
    print(f"HIBA: configs modul import sikertelen: {e}")
    sys.exit(1)

# --- LOGGOL√ÅS ---
logging.basicConfig(level=config.LOGGING_LEVEL, format=config.LOGGING_FORMAT)

# --- CSV FELDOLGOZ√ÅSI LIMIT N√ñVEL√âSE ---
# Sz√ºks√©ges a nagyon hossz√∫ sz√∂vegmez≈ëket tartalmaz√≥ sorok kezel√©s√©hez.
try:
    max_int = sys.maxsize
    while True:
        try:
            csv.field_size_limit(max_int)
            break
        except OverflowError:
            max_int = int(max_int / 10)
    logging.info(f"CSV field size limit be√°ll√≠tva: {max_int}")
except (ValueError, TypeError) as e:
    logging.warning(f"Nem siker√ºlt be√°ll√≠tani a CSV field size limitet: {e}")
    csv.field_size_limit(131072) # Default fallback

# --- GLOB√ÅLIS KONFIGUR√ÅCI√ì ---
MIN_TEXT_LENGTH = config.CLEANING_MIN_TEXT_LENGTH

def clean_text(text):
    """
    Sz√∂veg tiszt√≠t√°sa: speci√°lis karakterek, URL-ek, email c√≠mek √©s extra sz√≥k√∂z√∂k elt√°vol√≠t√°sa.
    """
    if not isinstance(text, str):
        return ""
    
    # \x00 null byte karakter elt√°vol√≠t√°sa
    text = text.replace('\x00', '')
    
    # URL-ek elt√°vol√≠t√°sa
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    
    # Email c√≠mek elt√°vol√≠t√°sa
    text = re.sub(r'\S+@\S+', '', text, flags=re.MULTILINE)
    
    # Nem-alfanumerikus karakterek elt√°vol√≠t√°sa (kiv√©ve pont, vessz≈ë, magyar √©kezetes karakterek)
    text = re.sub(r'[^\w\s.,-]', '', text)
    
    # T√∂bbsz√∂r√∂s sz√≥k√∂z√∂k, tabul√°torok, √∫j sorok cser√©je egyetlen sz√≥k√∂zre
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """
    A teljes DataFrame tiszt√≠t√°sa √©s sz≈±r√©se.
    """
    initial_rows = len(df)
    logging.info(f"DataFrame tiszt√≠t√°s√°nak kezdete {initial_rows:,} sorral.")

    # tqdm integr√°ci√≥ a pandas apply m≈±velethez
    tqdm.pandas(desc="Sz√∂vegtiszt√≠t√°s")

    # Sz√∂veg tiszt√≠t√°sa a 'text' oszlopon
    if 'text' in df.columns:
        df['cleaned_text'] = df['text'].astype(str).progress_apply(clean_text)
        logging.info("A 'text' oszlop tiszt√≠t√°sa befejez≈ëd√∂tt.")
    else:
        logging.warning("A 'text' oszlop nem tal√°lhat√≥ a DataFrame-ben. A sz√∂vegtiszt√≠t√°s kimarad.")
        df['cleaned_text'] = ''

    # √úres sz√∂vegek √©s t√∫l r√∂vid sz√∂vegek sz≈±r√©se
    df = df[df['cleaned_text'].str.len() >= MIN_TEXT_LENGTH]
    
    final_rows = len(df)
    removed_rows = initial_rows - final_rows
    logging.info(f"Sz≈±r√©s ut√°n {final_rows:,} sor maradt (elt√°vol√≠tva: {removed_rows:,}).")
    
    return df

def main():
    """
    F≈ë feldolgoz√°si logika.
    """
    logging.info("===== TISZT√çT√ÅSI √âS EL≈êK√âSZ√çT√âSI FOLYAMAT INDUL =====")
    
    in_path = config.RAW_CSV_DATA_PATH
    out_path = config.CLEANED_CSV_DATA_PATH

    if not in_path.exists():
        logging.error(f"A bemeneti f√°jl nem tal√°lhat√≥: {in_path}")
        print(f"‚ùå HIBA: A bemeneti f√°jl nem tal√°lhat√≥: {in_path}")
        print("K√©rlek, el≈ësz√∂r futtasd a `preprocess_documents.py` szkriptet.")
        return

    try:
        logging.info(f"Bemeneti CSV beolvas√°sa: {in_path}")
        df = pd.read_csv(
            in_path, 
            encoding=config.CSV_ENCODING, 
            quoting=csv.QUOTE_ALL,
            on_bad_lines='warn', # Hib√°s sorok jelz√©se
            engine='python' # Sz√ºks√©ges az on_bad_lines √©s a quoting be√°ll√≠t√°sokhoz
        )
        logging.info(f"Sikeresen beolvasva {len(df):,} sor.")
    except Exception as e:
        logging.error(f"Hiba a CSV beolvas√°sa k√∂zben: {e}")
        print(f"‚ùå HIBA a CSV beolvas√°sa k√∂zben. A r√©szletek√©rt l√°sd a log f√°jlt.")
        return

    # DataFrame tiszt√≠t√°sa
    cleaned_df = clean_dataframe(df)

    # Kimeneti mappa l√©trehoz√°sa, ha nem l√©tezik
    out_path.parent.mkdir(parents=True, exist_ok=True)
    
    try:
        logging.info(f"Tiszt√≠tott DataFrame ment√©se: {out_path}")
        cleaned_df.to_csv(
            out_path, 
            index=False, 
            encoding=config.CSV_ENCODING, 
            quoting=csv.QUOTE_ALL
        )
        logging.info(f"Sikeresen mentve {len(cleaned_df):,} sor.")
    except Exception as e:
        logging.error(f"Hiba a tiszt√≠tott CSV ment√©se k√∂zben: {e}")
        print(f"‚ùå HIBA a tiszt√≠tott CSV ment√©se k√∂zben. A r√©szletek√©rt l√°sd a log f√°jlt.")
        return

    # √ñsszegz√©s
    print("\n‚úÖ TISZT√çT√ÅS √âS EL≈êK√âSZ√çT√âS BEFEJEZVE!")
    print(f"üìÑ Bemeneti f√°jl: {in_path}")
    print(f"üìÑ Kimeneti f√°jl: {out_path}")
    print(f"üìä Eredeti sorok sz√°ma: {len(df):,}")
    print(f"üìä Tiszt√≠tott sorok sz√°ma (min. {MIN_TEXT_LENGTH} karakter): {len(cleaned_df):,}")

if __name__ == "__main__":
    main()