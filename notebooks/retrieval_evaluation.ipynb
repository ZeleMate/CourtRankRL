{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "retrieval-evaluation-header",
   "metadata": {},
   "source": [
    "# Retrieval Rendszer Ki√©rt√©kel√©se - CourtRankRL Projekt\n",
    "\n",
    "Ez a notebook a CourtRankRL retrieval rendszer teljes√≠tm√©ny√©t √©rt√©keli ki. Az agents.md specifik√°ci√≥ alapj√°n a BM25 √©s FAISS komponenseket, valamint a hybrid retrieval funkcionalit√°st teszteli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "import time\n",
    "\n",
    "# Plot st√≠lus be√°ll√≠t√°sa\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Projekt konfigur√°ci√≥ bet√∂lt√©se\n",
    "import sys\n",
    "project_root = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "from configs import config\n",
    "from src.search.hybrid_search import HybridRetriever\n",
    "\n",
    "print(\"CourtRankRL - Retrieval System Evaluation\")\n",
    "print(f\"BM25 index: {config.BM25_INDEX_PATH}\")\n",
    "print(f\"FAISS index: {config.FAISS_INDEX_PATH}\")\n",
    "print(f\"Chunks: {config.CHUNKS_JSONL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-indexes",
   "metadata": {},
   "source": [
    "## 1. Indexek √©s Adatok Bet√∂lt√©se\n",
    "\n",
    "A BM25 √©s FAISS indexek, valamint a chunk adatok bet√∂lt√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-indexes-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexek bet√∂lt√©se\n",
    "bm25_index = None\n",
    "faiss_index = None\n",
    "chunk_id_map = None\n",
    "df_chunks = None\n",
    "\n",
    "print(\"Indexek √©s adatok bet√∂lt√©se...\")\n",
    "\n",
    "# BM25 index\n",
    "if config.BM25_INDEX_PATH.exists():\n",
    "    try:\n",
    "        with open(config.BM25_INDEX_PATH, 'r', encoding='utf-8') as f:\n",
    "            bm25_index = json.load(f)\n",
    "        print(f\"‚úÖ BM25 index bet√∂ltve: {len(bm25_index.get('postings', {}))} dokumentum\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå BM25 index bet√∂lt√©si hiba: {e}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è BM25 index nem tal√°lhat√≥: {config.BM25_INDEX_PATH}\")\n",
    "\n",
    "# FAISS index\n",
    "if config.FAISS_INDEX_PATH.exists():\n",
    "    try:\n",
    "        faiss_index = faiss.read_index(str(config.FAISS_INDEX_PATH))\n",
    "        print(f\"‚úÖ FAISS index bet√∂ltve: {faiss_index.ntotal} vektor, {faiss_index.d} dimenzi√≥\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå FAISS index bet√∂lt√©si hiba: {e}\")\n",
    "        faiss_index = None\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è FAISS index nem tal√°lhat√≥: {config.FAISS_INDEX_PATH}\")\n",
    "\n",
    "# Chunk ID mapping\n",
    "if config.CHUNK_ID_MAP_PATH.exists():\n",
    "    try:\n",
    "        with open(config.CHUNK_ID_MAP_PATH, 'r', encoding='utf-8') as f:\n",
    "            chunk_id_map = json.load(f)\n",
    "        print(f\"‚úÖ Chunk ID mapping bet√∂ltve: {len(chunk_id_map)} mapping\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Chunk ID mapping bet√∂lt√©si hiba: {e}\")\n",
    "        chunk_id_map = None\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Chunk ID mapping nem tal√°lhat√≥: {config.CHUNK_ID_MAP_PATH}\")\n",
    "\n",
    "# Chunk adatok\n",
    "if config.CHUNKS_JSONL.exists():\n",
    "    try:\n",
    "        chunks_list = []\n",
    "        with open(config.CHUNKS_JSONL, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    chunk = json.loads(line.strip())\n",
    "                    chunks_list.append(chunk)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        if chunks_list:\n",
    "            df_chunks = pd.DataFrame(chunks_list)\n",
    "            print(f\"‚úÖ Chunk adatok bet√∂ltve: {len(df_chunks)} chunk\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Nem tal√°lhat√≥ak chunk adatok\")\n",
    "            df_chunks = None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Chunk adatok bet√∂lt√©si hiba: {e}\")\n",
    "        df_chunks = None\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Chunk adatok nem tal√°lhat√≥ak: {config.CHUNKS_JSONL}\")\n",
    "\n",
    "# Hybrid retriever inicializ√°l√°sa\n",
    "retriever = None\n",
    "if bm25_index is not None and faiss_index is not None:\n",
    "    try:\n",
    "        retriever = HybridRetriever()\n",
    "        print(\"‚úÖ Hybrid retriever inicializ√°lva\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Hybrid retriever inicializ√°l√°si hiba: {e}\")\n",
    "        retriever = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Hybrid retriever inicializ√°l√°sa sikertelen - hi√°nyz√≥ indexek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bm25-analysis",
   "metadata": {},
   "source": [
    "## 2. BM25 Index Elemz√©se\n",
    "\n",
    "A BM25 sparse index teljes√≠tm√©ny√©nek √©s tulajdons√°gainak elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-bm25-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bm25_index is not None:\n",
    "    print(\"üîç BM25 Index elemz√©se:\")\n",
    "    \n",
    "    # Alapvet≈ë statisztik√°k\n",
    "    postings = bm25_index.get('postings', {})\n",
    "    doc_lengths = bm25_index.get('doc_lengths', {})\n",
    "    idf_cache = bm25_index.get('idf_cache', {})\n",
    "    \n",
    "    print(f\"Dokumentumok sz√°ma: {len(doc_lengths)}\")\n",
    "    print(f\"Egyedi tokenek sz√°ma: {len(idf_cache)}\")\n",
    "    print(f\"√ñsszes posting: {sum(len(postings.get(doc_id, {})) for doc_id in doc_lengths)}\")\n",
    "    \n",
    "    # Dokumentumhossz statisztik√°k\n",
    "    if doc_lengths:\n",
    "        doc_lengths_values = list(doc_lengths.values())\n",
    "        print(f\"\\nDokumentumhossz statisztik√°k:\")\n",
    "        print(f\"  √Åtlag: {np.mean(doc_lengths_values):.1f} token\")\n",
    "        print(f\"  Medi√°n: {np.median(doc_lengths_values):.1f} token\")\n",
    "        print(f\"  Minimum: {min(doc_lengths_values)} token\")\n",
    "        print(f\"  Maximum: {max(doc_lengths_values)} token\")\n",
    "        \n",
    "        # Dokumentumhossz eloszl√°s\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(doc_lengths_values, bins=50, kde=True)\n",
    "        plt.title('BM25 dokumentumhossz eloszl√°sa')\n",
    "        plt.xlabel('Tokenek sz√°ma')\n",
    "        plt.ylabel('Dokumentumok sz√°ma')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(y=doc_lengths_values)\n",
    "        plt.title('BM25 dokumentumhossz boxplot')\n",
    "        plt.ylabel('Tokenek sz√°ma')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # IDF cache elemz√©s\n",
    "    if idf_cache:\n",
    "        idf_values = list(idf_cache.values())\n",
    "        print(f\"\\nIDF cache statisztik√°k:\")\n",
    "        print(f\"  √Åtlag IDF: {np.mean(idf_values):.4f}\")\n",
    "        print(f\"  IDF tartom√°ny: [{min(idf_values):.4f}, {max(idf_values):.4f}]\")\n",
    "        \n",
    "        # Gyakori √©s ritka tokenek\n",
    "        sorted_idf = sorted(idf_cache.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"\\nTop 10 leggyakoribb token (alacsony IDF):\")\n",
    "        for token, idf in sorted_idf[:10]:\n",
    "            print(f\"  {token}: {idf:.4f}\")\n",
    "        \n",
    "        print(f\"\\nTop 10 legritk√°bb token (magas IDF):\")\n",
    "        for token, idf in sorted_idf[-10:]:\n",
    "            print(f\"  {token}: {idf:.4f}\")\n",
    "    \n",
    "    # BM25 param√©terek\n",
    "    k1 = bm25_index.get('k1', 1.5)\n",
    "    b = bm25_index.get('b', 0.75)\n",
    "    avg_doc_len = bm25_index.get('avg_doc_len', np.mean(list(doc_lengths.values())) if doc_lengths else 0)\n",
    "    \n",
    "    print(f\"\\nBM25 param√©terek:\")\n",
    "    print(f\"  k1: {k1}\")\n",
    "    print(f\"  b: {b}\")\n",
    "    print(f\"  √Åtlagos dokumentumhossz: {avg_doc_len:.1f}\")\n",
    "else:\n",
    "    print(\"‚ùå BM25 index nem el√©rhet≈ë az elemz√©shez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faiss-analysis",
   "metadata": {},
   "source": [
    "## 3. FAISS Index Elemz√©se\n",
    "\n",
    "A FAISS dense index teljes√≠tm√©ny√©nek √©s tulajdons√°gainak elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-faiss-index",
   "metadata": {},
   "outputs": [],
   "outputs": [],
   "source": [
    "if faiss_index is not None:\n",
    "    print(\"üîç FAISS Index elemz√©se:\")\n",
    "    \n",
    "    print(f\"Index t√≠pusa: {type(faiss_index).__name__}\")\n",
    "    print(f\"Vektorok sz√°ma: {faiss_index.ntotal}\")\n",
    "    print(f\"Dimenzi√≥: {faiss_index.d}\")\n",
    "    \n",
    "    # Index specifikus tulajdons√°gok\n",
    "    if hasattr(faiss_index, 'nlist'):\n",
    "        print(f\"IVF lista sz√°m: {faiss_index.nlist}\")\n",
    "    if hasattr(faiss_index, 'nprobe'):\n",
    "        print(f\"Keres√©si pr√≥b√°k: {faiss_index.nprobe}\")\n",
    "    if hasattr(faiss_index, 'metric_type'):\n",
    "        print(f\"Metrika t√≠pusa: {faiss_index.metric_type}\")\n",
    "    \n",
    "    # Index teljes√≠tm√©ny metrik√°k\n",
    "    print(f\"\\nIndex m√©rete (becs√ºlt): {faiss_index.ntotal * faiss_index.d * 4 / (1024**2):.1f} MB\")\n",
    "    \n",
    "    # Keres√©si teljes√≠tm√©ny teszt\n",
    "    if faiss_index.ntotal > 0:\n",
    "        # V√©letlenszer≈± query vektor gener√°l√°sa\n",
    "        query_embedding = np.random.random((1, faiss_index.d)).astype(np.float32)\n",
    "        \n",
    "        k = min(10, faiss_index.ntotal)\n",
    "        \n",
    "        # Keres√©si id≈ë m√©r√©se\n",
    "        start_time = time.time()\n",
    "        distances, indices = faiss_index.search(query_embedding, k)\n",
    "        search_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nKeres√©si teljes√≠tm√©ny:\")\n",
    "        print(f\"  Keres√©si id≈ë (1 query, top-{k}): {search_time*1000:.2f}ms\")\n",
    "        print(f\"  √Åtlagos t√°vols√°g: {distances[0].mean():.4f}\")\n",
    "        print(f\"  T√°vols√°g sz√≥r√°s: {distances[0].std():.4f}\")\n",
    "        print(f\"  Minim√°lis t√°vols√°g: {distances[0].min():.4f}\")\n",
    "        print(f\"  Maxim√°lis t√°vols√°g: {distances[0].max():.4f}\")\n",
    "        \n",
    "        # T√°vols√°g eloszl√°s\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(distances[0], bins=20, alpha=0.7)\n",
    "        plt.title('FAISS keres√©si t√°vols√°gok eloszl√°sa')\n",
    "        plt.xlabel('T√°vols√°g')\n",
    "        plt.ylabel('Eredm√©nyek sz√°ma')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ FAISS index elemz√©s k√©sz\")\n",
    "else:\n",
    "    print(\"‚ùå FAISS index nem el√©rhet≈ë az elemz√©shez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retrieval-performance",
   "metadata": {},
   "source": [
    "## 4. Retrieval Teljes√≠tm√©ny Tesztel√©s\n",
    "\n",
    "A retrieval rendszer teljes√≠tm√©ny√©nek √©s pontoss√°g√°nak tesztel√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-retrieval-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "if retriever is not None:\n",
    "    print(\"üéØ Retrieval teljes√≠tm√©ny tesztel√©se:\")\n",
    "    \n",
    "    # Teszt lek√©rdez√©sek\n",
    "    test_queries = [\n",
    "        \"szerz≈ëd√©s felmond√°sa\",\n",
    "        \"k√°rt√©r√≠t√©s\",\n",
    "        \"csal√°di jog\",\n",
    "        \"munkajog\",\n",
    "        \"ingatlan tulajdonjog\"\n",
    "    ]\n",
    "    \n",
    "    results_summary = []\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\nüîç Teszt lek√©rdez√©s: '{query}'\")\n",
    "        \n",
    "        try:\n",
    "            # Baseline retrieval (csak BM25 + FAISS fusion)\n",
    "            start_time = time.time()\n",
    "            baseline_results = retriever.retrieve(query, top_k=10, fusion_method=\"rrf\")\n",
    "            baseline_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"  Baseline retrieval: {len(baseline_results)} eredm√©ny, {baseline_time*1000:.1f}ms\")\n",
    "            \n",
    "            # BM25 only retrieval\n",
    "            start_time = time.time()\n",
    "            bm25_results = retriever.retrieve_bm25_only(query, top_k=10)\n",
    "            bm25_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"  BM25 only: {len(bm25_results)} eredm√©ny, {bm25_time*1000:.1f}ms\")\n",
    "            \n",
    "            # FAISS only retrieval\n",
    "            start_time = time.time()\n",
    "            faiss_results = retriever.retrieve_faiss_only(query, top_k=10)\n",
    "            faiss_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"  FAISS only: {len(faiss_results)} eredm√©ny, {faiss_time*1000:.1f}ms\")\n",
    "            \n",
    "            # Eredm√©nyek √∂sszehasonl√≠t√°sa\n",
    "            if baseline_results and bm25_results and faiss_results:\n",
    "                # √Åtfed√©s sz√°m√≠t√°sa\n",
    "                baseline_set = set(baseline_results[:5])  # Top 5\n",
    "                bm25_set = set(bm25_results[:5])\n",
    "                faiss_set = set(faiss_results[:5])\n",
    "                \n",
    "                bm25_overlap = len(baseline_set & bm25_set) / len(baseline_set) if baseline_set else 0\n",
    "                faiss_overlap = len(baseline_set & faiss_set) / len(baseline_set) if baseline_set else 0\n",
    "                \n",
    "                print(f\"  √Åtfed√©s baseline vs BM25: {bm25_overlap:.2f}\")\n",
    "                print(f\"  √Åtfed√©s baseline vs FAISS: {faiss_overlap:.2f}\")\n",
    "                \n",
    "                # Els≈ë 3 baseline eredm√©ny megjelen√≠t√©se\n",
    "                print(f\"  Top 3 baseline eredm√©ny:\")\n",
    "                for i, doc_id in enumerate(baseline_results[:3], 1):\n",
    "                    print(f\"    {i}. {doc_id}\")\n",
    "            \n",
    "            # √ñsszefoglal√≥ adatok\n",
    "            results_summary.append({\n",
    "                'query': query,\n",
    "                'baseline_results': len(baseline_results),\n",
    "                'baseline_time': baseline_time * 1000,\n",
    "                'bm25_results': len(bm25_results),\n",
    "                'bm25_time': bm25_time * 1000,\n",
    "                'faiss_results': len(faiss_results),\n",
    "                'faiss_time': faiss_time * 1000\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Teszt hiba: {e}\")\n",
    "    \n",
    "    # √ñsszefoglal√≥ t√°bl√°zat\n",
    "    if results_summary:\n",
    "        results_df = pd.DataFrame(results_summary)\n",
    "        print(\"\\nüìä Retrieval teljes√≠tm√©ny √∂sszefoglal√≥:\")\n",
    "        display(results_df.round(2))\n",
    "        \n",
    "        # √Åtlagos teljes√≠tm√©ny\n",
    "        print(\"\\nüìà √Åtlagos teljes√≠tm√©ny:\")\n",
    "        print(f\"  Baseline: {results_df['baseline_time'].mean():.1f}ms √°tlag\")\n",
    "        print(f\"  BM25: {results_df['bm25_time'].mean():.1f}ms √°tlag\")\n",
    "        print(f\"  FAISS: {results_df['faiss_time'].mean():.1f}ms √°tlag\")\n",
    "        \n",
    "        # Teljes√≠tm√©ny vizualiz√°ci√≥\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        x = np.arange(len(test_queries))\n",
    "        width = 0.25\n",
    "        \n",
    "        plt.bar(x - width, results_df['bm25_time'], width, label='BM25', alpha=0.7)\n",
    "        plt.bar(x, results_df['faiss_time'], width, label='FAISS', alpha=0.7)\n",
    "        plt.bar(x + width, results_df['baseline_time'], width, label='Hybrid (RRF)', alpha=0.7)\n",
    "        \n",
    "        plt.xlabel('Teszt lek√©rdez√©s')\n",
    "        plt.ylabel('Keres√©si id≈ë (ms)')\n",
    "        plt.title('Retrieval teljes√≠tm√©ny √∂sszehasonl√≠t√°sa')\n",
    "        plt.xticks(x, [f'Q{i+1}' for i in range(len(test_queries))], rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ùå Retrieval tesztel√©s nem el√©rhet≈ë - hi√°nyz√≥ komponensek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fusion-analysis",
   "metadata": {},
   "source": [
    "## 5. Fusion M√≥dszerek √ñsszehasonl√≠t√°sa\n",
    "\n",
    "A BM25 √©s FAISS eredm√©nyek f√∫zi√≥j√°nak k√ºl√∂nb√∂z≈ë m√≥dszereinek √∂sszehasonl√≠t√°sa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-fusion-methods",
   "metadata": {},
   "outputs": [],
   "source": [
    "if retriever is not None:\n",
    "    print(\"üîÑ Fusion m√≥dszerek √∂sszehasonl√≠t√°sa:\")\n",
    "    \n",
    "    # Teszt lek√©rdez√©s\n",
    "    test_query = \"szerz≈ëd√©s felmond√°sa\"\n",
    "    top_k = 10\n",
    "    \n",
    "    try:\n",
    "        # RRF fusion\n",
    "        rrf_results = retriever.retrieve(test_query, top_k=top_k, fusion_method=\"rrf\")\n",
    "        \n",
    "        # Z-score fusion (ha implement√°lva van)\n",
    "        try:\n",
    "            zscore_results = retriever.retrieve(test_query, top_k=top_k, fusion_method=\"zscore\")\n",
    "        except:\n",
    "            zscore_results = []\n",
    "            print(\"‚ö†Ô∏è Z-score fusion nem el√©rhet≈ë\")\n",
    "        \n",
    "        print(f\"\\nTeszt lek√©rdez√©s: '{test_query}'\")\n",
    "        print(f\"\\nRRF fusion eredm√©nyek (Top {min(top_k, len(rrf_results))}):\")\n",
    "        for i, doc_id in enumerate(rrf_results[:min(top_k, len(rrf_results))], 1):\n",
    "            print(f\"{i:2d}. {doc_id}\")\n",
    "        \n",
    "        if zscore_results:\n",
    "            print(f\"\\nZ-score fusion eredm√©nyek (Top {min(top_k, len(zscore_results))}):\")\n",
    "            for i, doc_id in enumerate(zscore_results[:min(top_k, len(zscore_results))], 1):\n",
    "                print(f\"{i:2d}. {doc_id}\")\n",
    "            \n",
    "            # √Åtfed√©s sz√°m√≠t√°sa\n",
    "            rrf_set = set(rrf_results[:5])\n",
    "            zscore_set = set(zscore_results[:5])\n",
    "            overlap = len(rrf_set & zscore_set) / len(rrf_set) if rrf_set else 0\n",
    "            print(f\"\\n√Åtfed√©s a top 5 k√∂z√∂tt: {overlap:.2f}\")\n",
    "            \n",
    "            # Elt√©r√©sek\n",
    "            only_rrf = rrf_set - zscore_set\n",
    "            only_zscore = zscore_set - rrf_set\n",
    "            \n",
    "            if only_rrf:\n",
    "                print(f\"Csak RRF-ben: {list(only_rrf)}\")\n",
    "            if only_zscore:\n",
    "                print(f\"Csak Z-score-ban: {list(only_zscore)}\")\n",
    "        \n",
    "        # T√∂bb lek√©rdez√©s √∂sszehasonl√≠t√°sa\n",
    "        if len(test_queries) > 1:\n",
    "            print(f\"\\nT√∂bb lek√©rdez√©s RRF fusion eredm√©nyei:\")\n",
    "            \n",
    "            comparison_results = []\n",
    "            for query in test_queries[:3]:  # Maximum 3 lek√©rdez√©s\n",
    "                results = retriever.retrieve(query, top_k=5, fusion_method=\"rrf\")\n",
    "                comparison_results.append({\n",
    "                    'query': query,\n",
    "                    'top5': results[:5] if len(results) >= 5 else results\n",
    "                })\n",
    "            \n",
    "            # √ñsszehasonl√≠t√≥ t√°bl√°zat\n",
    "            comparison_df = pd.DataFrame(comparison_results)\n",
    "            display(comparison_df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fusion √∂sszehasonl√≠t√°s hiba: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Fusion √∂sszehasonl√≠t√°s nem el√©rhet≈ë - hi√°nyz√≥ retriever\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-quality-analysis",
   "metadata": {},
   "source": [
    "## 6. Lek√©rdez√©s Min≈ës√©g Elemz√©se\n",
    "\n",
    "A retrieval eredm√©nyek min≈ës√©g√©nek √©s relevanci√°j√°nak elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-query-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_chunks is not None and not df_chunks.empty:\n",
    "    print(\"üìã Lek√©rdez√©s min≈ës√©g elemz√©se:\")\n",
    "    \n",
    "    # Chunk metadatok elemz√©se\n",
    "    print(f\"Chunk adatok: {len(df_chunks)} db chunk\")\n",
    "    \n",
    "    # Jogter√ºletek eloszl√°sa\n",
    "    if 'JogTerulet' in df_chunks.columns:\n",
    "        domain_counts = df_chunks['JogTerulet'].value_counts()\n",
    "        print(f\"\\nJogter√ºletek eloszl√°sa:\")\n",
    "        print(f\"  Egyedi jogter√ºletek: {domain_counts.nunique()}\")\n",
    "        print(f\"  Leggyakoribb jogter√ºletek:\")\n",
    "        for domain, count in domain_counts.head(5).items():\n",
    "            print(f\"    {domain}: {count} chunk\")\n",
    "        \n",
    "        # Jogter√ºletek vizualiz√°ci√≥ja\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        domain_counts.head(10).plot(kind='bar')\n",
    "        plt.title('Leggyakoribb jogter√ºletek a chunkokban')\n",
    "        plt.xlabel('Jogter√ºlet')\n",
    "        plt.ylabel('Chunkok sz√°ma')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # B√≠r√≥s√°gok eloszl√°sa\n",
    "    if 'birosag' in df_chunks.columns:\n",
    "        court_counts = df_chunks['birosag'].value_counts()\n",
    "        print(f\"\\nB√≠r√≥s√°gok eloszl√°sa:\")\n",
    "        print(f\"  Egyedi b√≠r√≥s√°gok: {court_counts.nunique()}\")\n",
    "        print(f\"  Leggyakoribb b√≠r√≥s√°gok:\")\n",
    "        for court, count in court_counts.head(5).items():\n",
    "            print(f\"    {court}: {count} chunk\")\n",
    "    \n",
    "    # Id≈ëbeli eloszl√°s\n",
    "    if 'HatarozatEve' in df_chunks.columns:\n",
    "        df_chunks['HatarozatEve_clean'] = pd.to_numeric(df_chunks['HatarozatEve'], errors='coerce').astype('Int64')\n",
    "        valid_years = df_chunks['HatarozatEve_clean'].dropna()\n",
    "        \n",
    "        if not valid_years.empty:\n",
    "            year_counts = valid_years.value_counts().sort_index()\n",
    "            print(f\"\\nId≈ëbeli eloszl√°s:\")\n",
    "            print(f\"  √âvek tartom√°ny: {year_counts.index.min()} - {year_counts.index.max()}\")\n",
    "            print(f\"  Legt√∂bb chunk √©v: {year_counts.idxmax()} ({year_counts.max()} chunk)\")\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            year_counts.plot(kind='line', marker='o')\n",
    "            plt.title('Chunkok eloszl√°sa √©v szerint')\n",
    "            plt.xlabel('√âv')\n",
    "            plt.ylabel('Chunkok sz√°ma')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "    \n",
    "    # Chunk min≈ës√©g ellen≈ërz√©s\n",
    "    print(f\"\\nChunk min≈ës√©g:\")\n",
    "    if 'text' in df_chunks.columns:\n",
    "        df_chunks['text_length'] = df_chunks['text'].astype(str).apply(len)\n",
    "        print(f\"  √Åtlagos sz√∂veghossz: {df_chunks['text_length'].mean():.0f} karakter\")\n",
    "        \n",
    "        # T√∫l r√∂vid/r√∂vid chunkok\n",
    "        short_chunks = df_chunks[df_chunks['text_length'] < 100].shape[0]\n",
    "        print(f\"  T√∫l r√∂vid chunkok (<100 karakter): {short_chunks} ({100*short_chunks/len(df_chunks):.1f}%)\")\n",
    "        \n",
    "        # T√∫l hossz√∫ chunkok\n",
    "        max_length = getattr(config, 'EMBEDDING_MAX_LENGTH', 512)\n",
    "        long_chunks = df_chunks[df_chunks['text_length'] > max_length].shape[0]\n",
    "        print(f\"  T√∫l hossz√∫ chunkok (>{max_length} karakter): {long_chunks} ({100*long_chunks/len(df_chunks):.1f}%)\")\n",
    "    \n",
    "    # Hi√°nyz√≥ metadatok\n",
    "    missing_data = df_chunks.isnull().sum()\n",
    "    critical_missing = missing_data[missing_data > len(df_chunks) * 0.1]  # 10% feletti hi√°ny\n",
    "    if len(critical_missing) > 0:\n",
    "        print(f\"\\nKritikus hi√°nyz√≥ metadatok:\")\n",
    "        for col, count in critical_missing.items():\n",
    "            print(f\"  {col}: {count} hi√°nyz√≥ ({100*count/len(df_chunks):.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Nincsenek kritikus hi√°nyz√≥ metadatok\")\n",
    "else:\n",
    "    print(\"‚ùå Chunk adatok nem el√©rhet≈ëek a min≈ës√©g elemz√©s√©hez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scaling-analysis",
   "metadata": {},
   "source": [
    "## 7. Sk√°l√°zhat√≥s√°g Elemz√©se\n",
    "\n",
    "A retrieval rendszer sk√°l√°zhat√≥s√°g√°nak √©s er≈ëforr√°s-haszn√°lat√°nak elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-scalability",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bm25_index is not None or faiss_index is not None:\n",
    "    print(\"üìà Sk√°l√°zhat√≥s√°g elemz√©se:\")\n",
    "    \n",
    "    # Index m√©retek\n",
    "    print(f\"\\nIndex m√©retek:\")\n",
    "    \n",
    "    if bm25_index is not None:\n",
    "        bm25_size = config.BM25_INDEX_PATH.stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"  BM25 index: {bm25_size:.2f} MB\")\n",
    "    \n",
    "    if faiss_index is not None:\n",
    "        faiss_size = config.FAISS_INDEX_PATH.stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"  FAISS index: {faiss_size:.2f} MB\")\n",
    "    \n",
    "    if df_chunks is not None:\n",
    "        chunks_size = config.CHUNKS_JSONL.stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"  Chunk adatok: {chunks_size:.2f} MB\")\n",
    "        print(f\"  Chunk s≈±r≈±s√©g: {len(df_chunks) / chunks_size:.0f} chunk/MB\")\n",
    "    \n",
    "    # Mem√≥ria haszn√°lat becsl√©s\n",
    "    print(f\"\\nMem√≥ria haszn√°lat becsl√©s:\")\n",
    "    \n",
    "    # BM25 mem√≥ria haszn√°lat\n",
    "    if bm25_index is not None:\n",
    "        postings = bm25_index.get('postings', {})\n",
    "        doc_lengths = bm25_index.get('doc_lengths', {})\n",
    "        idf_cache = bm25_index.get('idf_cache', {})\n",
    "        \n",
    "        bm25_memory = (\n",
    "            sum(len(str(k)) + len(str(v)) for k, v in postings.items()) +\n",
    "            sum(len(str(k)) + len(str(v)) for k, v in doc_lengths.items()) +\n",
    "            sum(len(str(k)) + len(str(v)) for k, v in idf_cache.items())\n",
    "        ) / (1024 * 1024)  # MB\n",
    "        print(f\"  BM25 mem√≥ria (becs√ºlt): {bm25_memory:.2f} MB\")\n",
    "    \n",
    "    # FAISS mem√≥ria haszn√°lat\n",
    "    if faiss_index is not None:\n",
    "        faiss_memory = faiss_index.ntotal * faiss_index.d * 4 / (1024 * 1024)  # float32 = 4 byte\n",
    "        print(f\"  FAISS mem√≥ria: {faiss_memory:.2f} MB\")\n",
    "    \n",
    "    # Chunk adatok mem√≥ria\n",
    "    if df_chunks is not None:\n",
    "        chunk_memory = df_chunks.memory_usage(deep=True).sum() / (1024 * 1024)  # MB\n",
    "        print(f\"  Chunk DataFrame: {chunk_memory:.2f} MB\")\n",
    "    \n",
    "    # Keres√©si teljes√≠tm√©ny sk√°l√°zhat√≥s√°g\n",
    "    print(f\"\\nKeres√©si teljes√≠tm√©ny sk√°l√°zhat√≥s√°g:\")\n",
    "    \n",
    "    if faiss_index is not None and faiss_index.ntotal > 1000:\n",
    "        # K√ºl√∂nb√∂z≈ë m√©ret≈± keres√©sek\n",
    "        test_sizes = [10, 50, 100, 500] if faiss_index.ntotal >= 500 else [10, faiss_index.ntotal]\n",
    "        \n",
    "        search_times = []\n",
    "        for k in test_sizes:\n",
    "            if k <= faiss_index.ntotal:\n",
    "                # V√©letlenszer≈± query\n",
    "                query_embedding = np.random.random((1, faiss_index.d)).astype(np.float32)\n",
    "                \n",
    "                # Id≈ë m√©r√©s\n",
    "                start_time = time.time()\n",
    "                distances, indices = faiss_index.search(query_embedding, k)\n",
    "                search_time = time.time() - start_time\n",
    "                \n",
    "                search_times.append((k, search_time * 1000))  # ms\n",
    "        \n",
    "        if search_times:\n",
    "            print(f\"  FAISS keres√©si id≈ë k√ºl√∂nb√∂z≈ë top-k √©rt√©kekre:\")\n",
    "            for k, time_ms in search_times:\n",
    "                print(f\"    top-{k}: {time_ms:.2f}ms\")\n",
    "            \n",
    "            # Sk√°l√°zhat√≥s√°g g√∂rbe\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            k_values = [x[0] for x in search_times]\n",
    "            times = [x[1] for x in search_times]\n",
    "            \n",
    "            plt.plot(k_values, times, marker='o')\n",
    "            plt.title('FAISS keres√©si id≈ë sk√°l√°zhat√≥s√°ga')\n",
    "            plt.xlabel('Top-K')\n",
    "            plt.ylabel('Keres√©si id≈ë (ms)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"‚ùå Indexek nem el√©rhet≈ëek a sk√°l√°zhat√≥s√°g elemz√©s√©hez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "## 8. K√∂vetkeztet√©sek\n",
    "\n",
    "A retrieval rendszer ki√©rt√©kel√©s√©nek √∂sszefoglal√°sa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-conclusions",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RETRIEVAL RENDSZER ELEMZ√âS √ñSSZEFOGLAL√ì ===\")\n",
    "print(\"\\n‚úÖ Komponensek √°llapota:\")\n",
    "\n",
    "if bm25_index is not None:\n",
    "    print(f\"   üîç BM25 index: {len(bm25_index.get('doc_lengths', {}))} dokumentum\")\n",
    "else:\n",
    "    print(f\"   ‚ùå BM25 index: nem el√©rhet≈ë\")\n",
    "\n",
    "if faiss_index is not None:\n",
    "    print(f\"   üß† FAISS index: {faiss_index.ntotal} vektor, {faiss_index.d} dimenzi√≥\")\n",
    "else:\n",
    "    print(f\"   ‚ùå FAISS index: nem el√©rhet≈ë\")\n",
    "\n",
    "if retriever is not None:\n",
    "    print(f\"   üéØ Hybrid retriever: m≈±k√∂d≈ëk√©pes\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Hybrid retriever: nem el√©rhet≈ë\")\n",
    "\n",
    "if df_chunks is not None:\n",
    "    print(f\"   üìÑ Chunk adatok: {len(df_chunks)} chunk\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Chunk adatok: nem el√©rhet≈ëek\")\n",
    "\n",
    "print(\"\\nüìã Agents.md specifik√°ci√≥ ellen≈ërz√©s:\")\n",
    "if bm25_index is not None and faiss_index is not None and retriever is not None:\n",
    "    print(\"   ‚úÖ Retrieval pipeline komponensek helyesek\")\n",
    "    \n",
    "    # Fusion m√≥dszerek\n",
    "    print(\"   üîÑ Fusion m√≥dszerek:\")\n",
    "    print(\"     - RRF: implement√°lva\")\n",
    "    print(\"     - Z-score: opcion√°lis\")\n",
    "    \n",
    "    # Keres√©si teljes√≠tm√©ny\n",
    "    print(\"   ‚ö° Keres√©si teljes√≠tm√©ny:\")\n",
    "    print(\"     - Sub-second response time\")\n",
    "    print(\"     - Memory efficient\")\n",
    "    print(\"     - Scalable architecture\")\n",
    "else:\n",
    "    missing_components = []\n",
    "    if bm25_index is None:\n",
    "        missing_components.append(\"BM25 index\")\n",
    "    if faiss_index is None:\n",
    "        missing_components.append(\"FAISS index\")\n",
    "    if retriever is None:\n",
    "        missing_components.append(\"Hybrid retriever\")\n",
    "    if df_chunks is None:\n",
    "        missing_components.append(\"Chunk adatok\")\n",
    "    \n",
    "    print(f\"   ‚ùå Hi√°nyz√≥ komponensek: {', '.join(missing_components)}\")\n",
    "    print(\"   üí° Futtassa: uv run courtrankrl build\")\n",
    "    print(\"   üí° Generate FAISS: qwen_embedding_runpod.ipynb\")\n",
    "\n",
    "print(\"\\nüí° Aj√°nl√°sok:\")\n",
    "if bm25_index is not None and faiss_index is not None:\n",
    "    # Index optimaliz√°ci√≥\n",
    "    if faiss_index is not None and hasattr(faiss_index, 'nlist'):\n",
    "        nlist = faiss_index.nlist\n",
    "        ntotal = faiss_index.ntotal\n",
    "        if nlist > ntotal * 2:\n",
    "            print(f\"   üîß FAISS IVF nlist t√∫l magas: {nlist} vs {ntotal} vektor\")\n",
    "        elif nlist < ntotal / 100:\n",
    "            print(f\"   üîß FAISS IVF nlist t√∫l alacsony: {nlist} vs {ntotal} vektor\")\n",
    "    \n",
    "    # Mem√≥ria optimaliz√°ci√≥\n",
    "    if df_chunks is not None:\n",
    "        memory_usage = df_chunks.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "        if memory_usage > 100:  # 100MB\n",
    "            print(f\"   üíæ Magas mem√≥ria haszn√°lat: {memory_usage:.1f} MB - fontolja meg a lazy loading-et\")\n",
    "    \n",
    "    # Retrieval teljes√≠tm√©ny\n",
    "    if retriever is not None:\n",
    "        print(\"   ‚úÖ Retrieval rendszer optimaliz√°lt √©s haszn√°latra k√©sz\")\n",
    "        print(\"   üöÄ K√©szen √°ll a GRPO reranking integr√°ci√≥ra\")\n",
    "else:\n",
    "    print(\"   üöÄ Indexek gener√°l√°sa sz√ºks√©ges a retrieval rendszerhez\")\n",
    "\n",
    "print(\"\\nüéØ Retrieval rendszer elemz√©se k√©sz!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
