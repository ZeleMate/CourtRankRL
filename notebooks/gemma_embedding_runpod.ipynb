{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CourtRankRL Embedding Generation - Sentence Transformers (RTX 5090 GPU)\n",
        "\n",
        "## Specifik√°ci√≥\n",
        "- **Modell**: google/embeddinggemma-300m via Sentence Transformers (>=5.1.0)\n",
        "- **Input**: chunks.jsonl (processed court decisions)\n",
        "- **Output**: embeddings.npy (float32, L2-normalized) √©s embedding_chunk_ids.json\n",
        "- **K√∂rnyezet**: RunPod RTX 5090 GPU (24GB VRAM)\n",
        "- **Batch size**: 512 (GPU optimaliz√°lt)\n",
        "- **Kritikus**: CSAK Sentence Transformers - AutoModel ZERO VECTOR-t produk√°l!\n",
        "\n",
        "## Prompt-ok (automatikus Sentence Transformers-ben)\n",
        "- **Document chunks**: `prompt_name=\"document\"` ‚Üí \"title: none | text: {chunk_text}\"\n",
        "- **Query**: `prompt_name=\"query\"` ‚Üí \"task: search result | query: {query_text}\"\n",
        "- **Normalization**: `normalize_embeddings=True` (automatikus L2-normaliz√°l√°s)\n",
        "\n",
        "## Mem√≥ria kezel√©s\n",
        "- Shard-okba √≠r√°s nagy dataset-ekhez\n",
        "- Konszolid√°ci√≥ a v√©g√©n\n",
        "- GPU mem√≥ria monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bd5c1a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# KRITIKUS: Csak Sentence Transformers - AutoModel ZERO VECTOR-t produk√°l!\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import psutil\n",
        "from typing import List\n",
        "import torch\n",
        "\n",
        "# --- Konfigur√°ci√≥ ---\n",
        "BASE_PATH = Path(\"/workspace\")\n",
        "CHUNKS_PATH = BASE_PATH / \"chunks.jsonl\"\n",
        "EMBEDDINGS_PATH = BASE_PATH / \"embeddings.npy\"\n",
        "CHUNK_IDS_PATH = BASE_PATH / \"embedding_chunk_ids.json\"\n",
        "\n",
        "# GPU konfigur√°ci√≥ RTX 5090-hez\n",
        "BATCH_SIZE = 512\n",
        "MAX_SEQ_LENGTH = 2048  # EmbeddingGemma default\n",
        "SHARD_SIZE = 100_000  # Shard-okba √≠r√°s\n",
        "\n",
        "# HF token (k√∂rnyezeti v√°ltoz√≥b√≥l)\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "if not HF_TOKEN:\n",
        "    raise ValueError(\"‚ùå HF_TOKEN k√∂rnyezeti v√°ltoz√≥ hi√°nyzik!\")\n",
        "\n",
        "print(f\"üöÄ RTX 5090 Embedding Generation indul...\")\n",
        "print(f\"üìÇ Base path: {BASE_PATH}\")\n",
        "print(f\"üìÑ Input chunks: {CHUNKS_PATH}\")\n",
        "print(f\"üìÑ Output embeddings: {EMBEDDINGS_PATH}\")\n",
        "print(f\"üìÑ Output chunk IDs: {CHUNK_IDS_PATH}\")\n",
        "\n",
        "# --- Chunks bet√∂lt√©s (pandas optimaliz√°lt - agents.md szerint) ---\n",
        "def load_chunks(chunks_path: Path) -> List[dict]:\n",
        "    \"\"\"\n",
        "    Chunks bet√∂lt√©se JSONL-b≈ël pandas seg√≠ts√©g√©vel.\n",
        "    \n",
        "    pandas.read_json() 10-30x gyorsabb mint k√©zi json.loads() parsing.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    \n",
        "    print(f\"üì• Chunks bet√∂lt√©se: {chunks_path}\")\n",
        "    \n",
        "    try:\n",
        "        # pandas.read_json() C-optimaliz√°lt, sokkal gyorsabb\n",
        "        df_chunks = pd.read_json(chunks_path, lines=True, encoding='utf-8')\n",
        "        chunks = df_chunks.to_dict('records')\n",
        "        print(f\"‚úÖ {len(chunks):,} chunks bet√∂ltve\")\n",
        "    except (ValueError, FileNotFoundError) as e:\n",
        "        print(f\"‚ùå Hiba a chunks bet√∂lt√©se sor√°n: {e}\")\n",
        "        chunks = []\n",
        "    \n",
        "    return chunks\n",
        "\n",
        "chunks = load_chunks(CHUNKS_PATH)\n",
        "chunk_texts = [chunk['text'] for chunk in chunks]\n",
        "chunk_ids = [chunk['chunk_id'] for chunk in chunks]\n",
        "\n",
        "print(f\"üìä √ñsszes chunk: {len(chunk_texts):,}\")\n",
        "print(f\"üíæ Mem√≥ria haszn√°lat: {psutil.virtual_memory().used / 1024**3:.1f}GB\")\n",
        "\n",
        "# --- Modell bet√∂lt√©s (CSAK Sentence Transformers!) ---\n",
        "print(\"ü§ñ EmbeddingGemma modell bet√∂lt√©se (Sentence Transformers)...\")\n",
        "\n",
        "try:\n",
        "    model = SentenceTransformer(\n",
        "        \"google/embeddinggemma-300m\",\n",
        "        token=HF_TOKEN,\n",
        "        trust_remote_code=True,\n",
        "        cache_dir=\"/tmp/hf_cache\"\n",
        "    )\n",
        "    print(\"‚úÖ Modell bet√∂ltve (Sentence Transformers)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Modell bet√∂lt√©si hiba: {e}\")\n",
        "    raise\n",
        "\n",
        "# GPU be√°ll√≠t√°sok\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = model.to(device)\n",
        "    print(f\"‚úÖ GPU el√©rhet≈ë: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"üíæ GPU mem√≥ria: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"‚ö†Ô∏è GPU nem el√©rhet≈ë - CPU haszn√°lata (lass√∫!)\")\n",
        "\n",
        "# --- Embedding gener√°l√°s ---\n",
        "def generate_embeddings(model, texts: List[str], batch_size: int, device) -> np.ndarray:\n",
        "    \"\"\"Batch-es embedding gener√°l√°s\"\"\"\n",
        "    print(f\"üîÑ Embedding gener√°l√°s indul: {len(texts):,} texts\")\n",
        "    \n",
        "    all_embeddings = []\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Batch-ek feldolgoz√°sa\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        batch_start = time.time()\n",
        "        \n",
        "        try:\n",
        "            # KRITIKUS: Sentence Transformers encode() haszn√°lata\n",
        "            # Automatikus prompt: \"title: none | text: {chunk}\"\n",
        "            # Automatikus L2-normaliz√°l√°s\n",
        "            batch_embeddings = model.encode(\n",
        "                batch_texts,\n",
        "                prompt_name=\"document\",  # Document prompt\n",
        "                normalize_embeddings=True,  # L2-normaliz√°l√°s\n",
        "                batch_size=batch_size,\n",
        "                convert_to_numpy=True,\n",
        "                device=device,\n",
        "                show_progress_bar=True\n",
        "                # dtype=torch.float32 ELT√ÅVOL√çTVA - nem t√°mogatott param√©ter!\n",
        "            )\n",
        "            \n",
        "            all_embeddings.append(batch_embeddings)\n",
        "            \n",
        "            # GPU mem√≥ria monitoring\n",
        "            if device.type == 'cuda':\n",
        "                mem_used = torch.cuda.memory_allocated() / 1024**3\n",
        "                print(f\"  üìä Batch {i//batch_size + 1} k√©sz | GPU mem√≥ria: {mem_used:.1f}GB\")\n",
        "            \n",
        "            batch_time = time.time() - batch_start\n",
        "            print(f\"  ‚è±Ô∏è Batch id≈ë: {batch_time:.2f}s\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Batch hiba {i//batch_size + 1}-n√°l: {e}\")\n",
        "            raise\n",
        "    \n",
        "    # Konszolid√°ci√≥\n",
        "    embeddings = np.vstack(all_embeddings)\n",
        "    total_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"‚úÖ Embedding gener√°l√°s k√©sz: {embeddings.shape}\")\n",
        "    print(f\"‚è±Ô∏è Teljes id≈ë: {total_time:.2f}s\")\n",
        "    print(f\"‚ö° Sebess√©g: {len(texts)/total_time:.1f} texts/sec\")\n",
        "    \n",
        "    return embeddings\n",
        "\n",
        "# Sanity check: Ellen≈ërizz√ºk hogy nincsenek zero vector-ok\n",
        "def validate_embeddings(embeddings: np.ndarray, chunk_ids: List[str]) -> tuple:\n",
        "    \"\"\"Embedding valid√°ci√≥ √©s tiszt√≠t√°s\"\"\"\n",
        "    print(\"üîç Embedding valid√°ci√≥...\")\n",
        "    \n",
        "    # NaN/Inf ellen≈ërz√©s\n",
        "    finite_mask = np.isfinite(embeddings).all(axis=1)\n",
        "    print(f\"  üìä Finite embeddings: {finite_mask.sum():,}/{len(embeddings):,}\")\n",
        "    \n",
        "    # Zero norma ellen≈ërz√©s\n",
        "    norms = np.linalg.norm(embeddings, axis=1)\n",
        "    nonzero_mask = norms > 1e-6\n",
        "    print(f\"  üìä Non-zero norm embeddings: {nonzero_mask.sum():,}/{len(embeddings):,}\")\n",
        "    \n",
        "    # Kombin√°lt maszk\n",
        "    valid_mask = finite_mask & nonzero_mask\n",
        "    num_invalid = (~valid_mask).sum()\n",
        "    \n",
        "    if num_invalid > 0:\n",
        "        print(f\"‚ö†Ô∏è {num_invalid:,} invalid embedding kisz≈±rve\")\n",
        "        embeddings = embeddings[valid_mask]\n",
        "        chunk_ids = [cid for cid, keep in zip(chunk_ids, valid_mask) if keep]\n",
        "    else:\n",
        "        print(\"‚úÖ Minden embedding valid\")\n",
        "    \n",
        "    return embeddings, chunk_ids\n",
        "\n",
        "# Gener√°l√°s\n",
        "embeddings = generate_embeddings(model, chunk_texts, BATCH_SIZE, device)\n",
        "\n",
        "# Valid√°ci√≥ √©s tiszt√≠t√°s\n",
        "embeddings, chunk_ids = validate_embeddings(embeddings, chunk_ids)\n",
        "\n",
        "# V√©gs≈ë dtype biztos√≠t√°s\n",
        "if embeddings.dtype != np.float32:\n",
        "    embeddings = embeddings.astype(np.float32)\n",
        "\n",
        "print(f\"üéØ V√©gs≈ë alak: {embeddings.shape}\")\n",
        "print(f\"üíæ Mem√≥ria haszn√°lat: {embeddings.nbytes / 1024**3:.2f}GB\")\n",
        "\n",
        "# --- Ment√©s shard-okba (nagy dataset-ekhez) ---\n",
        "def save_sharded_embeddings(embeddings: np.ndarray, chunk_ids: List[str], \n",
        "                           shard_size: int, output_path: Path, ids_path: Path):\n",
        "    \"\"\"Shard-okba ment√©s mem√≥ria optimaliz√°l√°shoz\"\"\"\n",
        "    print(f\"üíæ Shard-okba ment√©s (shard size: {shard_size:,})...\")\n",
        "    \n",
        "    os.makedirs(output_path.parent, exist_ok=True)\n",
        "    os.makedirs(ids_path.parent, exist_ok=True)\n",
        "    \n",
        "    # Shard-ok l√©trehoz√°sa\n",
        "    for i in range(0, len(embeddings), shard_size):\n",
        "        shard_idx = i // shard_size\n",
        "        end_idx = min(i + shard_size, len(embeddings))\n",
        "        \n",
        "        shard_embeddings = embeddings[i:end_idx]\n",
        "        shard_ids = chunk_ids[i:end_idx]\n",
        "        \n",
        "        shard_path = output_path.parent / f\"embeddings_shard_{shard_idx}.npy\"\n",
        "        ids_shard_path = output_path.parent / f\"chunk_ids_shard_{shard_idx}.json\"\n",
        "        \n",
        "        np.save(shard_path, shard_embeddings)\n",
        "        with open(ids_shard_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(shard_ids, f, ensure_ascii=False, indent=2)\n",
        "        \n",
        "        print(f\"  üíæ Shard {shard_idx} mentve: {len(shard_embeddings):,} embeddings\")\n",
        "    \n",
        "    # Konszolid√°lt f√°jlok l√©trehoz√°sa\n",
        "    print(\"üîÑ Konszolid√°ci√≥ shard-okb√≥l...\")\n",
        "    \n",
        "    # Embeddings √∂sszevon√°sa\n",
        "    consolidated_embeddings = []\n",
        "    consolidated_ids = []\n",
        "    \n",
        "    shard_idx = 0\n",
        "    while True:\n",
        "        shard_path = output_path.parent / f\"embeddings_shard_{shard_idx}.npy\"\n",
        "        ids_shard_path = output_path.parent / f\"chunk_ids_shard_{shard_idx}.json\"\n",
        "        \n",
        "        if not shard_path.exists():\n",
        "            break\n",
        "            \n",
        "        shard_emb = np.load(shard_path)\n",
        "        with open(ids_shard_path, 'r', encoding='utf-8') as f:\n",
        "            shard_ids = json.load(f)\n",
        "        \n",
        "        consolidated_embeddings.append(shard_emb)\n",
        "        consolidated_ids.extend(shard_ids)\n",
        "        \n",
        "        # Tiszt√≠t√°s\n",
        "        os.remove(shard_path)\n",
        "        os.remove(ids_shard_path)\n",
        "        \n",
        "        shard_idx += 1\n",
        "    \n",
        "    # V√©gs≈ë konszolid√°ci√≥\n",
        "    final_embeddings = np.vstack(consolidated_embeddings)\n",
        "    print(f\"‚úÖ Konszolid√°lt: {final_embeddings.shape}\")\n",
        "    \n",
        "    # Ment√©s\n",
        "    np.save(output_path, final_embeddings)\n",
        "    with open(ids_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(consolidated_ids, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"üíæ Konszolid√°lt f√°jlok mentve\")\n",
        "\n",
        "# Ment√©s\n",
        "save_sharded_embeddings(embeddings, chunk_ids, SHARD_SIZE, EMBEDDINGS_PATH, CHUNK_IDS_PATH)\n",
        "\n",
        "# --- V√©gs≈ë valid√°ci√≥ ---\n",
        "print(\"üîç V√©gs≈ë valid√°ci√≥...\")\n",
        "\n",
        "# Bet√∂lt√©s ellen≈ërz√©s\n",
        "loaded_embeddings = np.load(EMBEDDINGS_PATH)\n",
        "with open(CHUNK_IDS_PATH, 'r', encoding='utf-8') as f:\n",
        "    loaded_ids = json.load(f)\n",
        "\n",
        "# Ellen≈ërz√©sek\n",
        "assert loaded_embeddings.shape[0] == len(loaded_ids), \"ID √©s embedding sz√°m nem egyezik\"\n",
        "assert loaded_embeddings.shape[1] == 768, f\"Embedding dim nem 768: {loaded_embeddings.shape[1]}\"\n",
        "assert loaded_embeddings.dtype == np.float32, f\"Dtype nem float32: {loaded_embeddings.dtype}\"\n",
        "\n",
        "# NaN/Inf ellen≈ërz√©s\n",
        "assert np.isfinite(loaded_embeddings).all(), \"NaN/Inf az embeddingekben!\"\n",
        "assert np.all(np.linalg.norm(loaded_embeddings, axis=1) > 0), \"Zero-norm embeddings!\"\n",
        "\n",
        "print(\"‚úÖ V√©gs≈ë valid√°ci√≥ sikeres\")\n",
        "print(f\"üìä V√©gs≈ë statisztik√°k:\")\n",
        "print(f\"  ‚Ä¢ Embeddings: {loaded_embeddings.shape}\")\n",
        "print(f\"  ‚Ä¢ Chunk IDs: {len(loaded_ids)}\")\n",
        "print(f\"  ‚Ä¢ Mem√≥ria: {loaded_embeddings.nbytes / 1024**3:.2f}GB\")\n",
        "\n",
        "# --- √ñsszefoglal√≥ ---\n",
        "print(\"=\"*80)\n",
        "print(\"üéâ EMBEDDING GENER√ÅL√ÅS SIKERES!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"üìÑ Kimeneti f√°jlok:\")\n",
        "print(f\"  ‚Ä¢ {EMBEDDINGS_PATH}\")\n",
        "print(f\"  ‚Ä¢ {CHUNK_IDS_PATH}\")\n",
        "print(f\"üìä Vektorok: {loaded_embeddings.shape[0]:,}\")\n",
        "print(f\"üéØ Dimenzi√≥: {loaded_embeddings.shape[1]}\")\n",
        "print(f\"üíæ F√°jlm√©ret: {EMBEDDINGS_PATH.stat().st_size / 1024**3:.2f}GB\")\n",
        "print(f\"‚è±Ô∏è Futtat√°si id≈ë: {time.time() - time.time():.2f}s\")  # TODO: Track total time\n",
        "\n",
        "print(\"\n",
        "üöÄ K√∂vetkez≈ë l√©p√©s: T√∂ltsd le az artifact-okat √©s futtasd a faiss_index_builder.ipynb-t\")\n",
        "print(\"üí° Tipp: Ellen≈ërizd hogy minden embedding L2-normaliz√°lt √©s finite!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "487faf93",
      "metadata": {},
      "source": [
        "## Haszn√°lat\n",
        "\n",
        "\n",
        "\n",
        "## Kritikus megjegyz√©sek\n",
        "\n",
        "1. **CSAK Sentence Transformers!** AutoModel haszn√°lata zero-vector-t produk√°l\n",
        "2. **normalize_embeddings=True** k√∂telez≈ë az L2-normaliz√°l√°shoz\n",
        "3. **float32** haszn√°lata - EmbeddingGemma nem t√°mogatja float16-ot\n",
        "4. **prompt_name=\"document\"** automatikusan hozz√°adja a megfelel≈ë prompt-ot\n",
        "5. **Valid√°ci√≥** minden embedding-re - zero vector-ok azonnali detekt√°l√°sa\n",
        "6. **dtype param√©ter ELT√ÅVOL√çTVA** - Sentence Transformers nem t√°mogatja ezt a param√©tert"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
