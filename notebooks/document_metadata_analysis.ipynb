{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "document-metadata-analysis-header",
   "metadata": {},
   "source": [
    "# Dokumentum Metadatok Ki√©rt√©kel√©se - CourtRankRL Projekt\n",
    "\n",
    "Ez a notebook a processed_docs.jsonl f√°jlban tal√°lhat√≥ dokumentum metadatokat elemzi. Az agents.md specifik√°ci√≥ alapj√°n k√©sz√≠tett ki√©rt√©kel√©si szempontokat vizsg√°lja a jelenlegi adatokkal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-config",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Projekt konfigur√°ci√≥ bet√∂lt√©se\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m project_root = Path(\u001b[34;43m__file__\u001b[39;49m).parent.parent\n\u001b[32m     18\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(project_root))\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfigs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Plot st√≠lus be√°ll√≠t√°sa\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Projekt konfigur√°ci√≥ bet√∂lt√©se\n",
    "import sys\n",
    "project_root = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "from configs import config\n",
    "\n",
    "print(\"CourtRankRL - Document Metadata Analysis\")\n",
    "print(f\"Processed docs: {config.PROCESSED_DOCS_LIST}\")\n",
    "print(f\"Chunks: {config.CHUNKS_JSONL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-processed-docs",
   "metadata": {},
   "source": [
    "## 1. Feldolgozott Dokumentumok Bet√∂lt√©se\n",
    "\n",
    "A processed_docs.jsonl f√°jl bet√∂lt√©se a metadatok elemz√©s√©hez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-processed-docs-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processed docs bet√∂lt√©se\n",
    "processed_docs_file = config.PROCESSED_DOCS_LIST\n",
    "df = None\n",
    "\n",
    "print(f\"Processed docs bet√∂lt√©se: {processed_docs_file}\")\n",
    "\n",
    "if processed_docs_file.exists():\n",
    "    try:\n",
    "        processed_docs_list = []\n",
    "        with open(processed_docs_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    doc = json.loads(line.strip())\n",
    "                    processed_docs_list.append(doc)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        if processed_docs_list:\n",
    "            df = pd.DataFrame(processed_docs_list)\n",
    "            print(f\"‚úÖ Bet√∂lt√∂tt dokumentumok sz√°ma: {len(df)}\")\n",
    "            print(f\"Oszlopok: {df.columns.tolist()}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Nem tal√°lhat√≥ak feldolgozhat√≥ dokumentumok\")\n",
    "            df = None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Hiba a dokumentumok bet√∂lt√©se sor√°n: {e}\")\n",
    "        df = None\n",
    "else:\n",
    "    print(f\"‚ùå Processed docs f√°jl nem tal√°lhat√≥: {processed_docs_file}\")\n",
    "    print(\"Futtassa a build pipeline-t el≈ësz√∂r: uv run courtrankrl build\")\n",
    "    df = None\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    print(f\"\\nAdatok bet√∂ltve: {df.shape[0]} dokumentum, {df.shape[1]} oszlop\")\n",
    "    print(f\"Els≈ë n√©h√°ny sor:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"\\n‚ùå Nincs adat az elemz√©shez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-info-analysis",
   "metadata": {},
   "source": [
    "## 2. Alapvet≈ë Inform√°ci√≥k √©s Statisztik√°k\n",
    "\n",
    "A dokumentum metadatok alapvet≈ë statisztik√°inak elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-basic-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"üìä Alapvet≈ë inform√°ci√≥k:\")\n",
    "    print(f\"Dokumentumok sz√°ma: {len(df)}\")\n",
    "    print(f\"Oszlopok: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Adatt√≠pusok\n",
    "    print(f\"\\nAdatt√≠pusok:\")\n",
    "    df.info()\n",
    "    \n",
    "    # Le√≠r√≥ statisztik√°k\n",
    "    print(\"\\nüìà Le√≠r√≥ statisztik√°k (numerikus oszlopok):\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        display(df[numeric_cols].describe())\n",
    "    \n",
    "    print(\"\\nüìã Le√≠r√≥ statisztik√°k (kategorikus oszlopok):\")\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        display(df[categorical_cols].describe())\n",
    "else:\n",
    "    print(\"‚ùå Nincs adat az alapvet≈ë inform√°ci√≥k elemz√©s√©hez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-values-analysis",
   "metadata": {},
   "source": [
    "## 3. Hi√°nyz√≥ √ârt√©kek Elemz√©se\n",
    "\n",
    "A hi√°nyz√≥ √©rt√©kek azonos√≠t√°sa √©s vizualiz√°ci√≥ja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-missing-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"üîç Hi√°nyz√≥ √©rt√©kek elemz√©se:\")\n",
    "    \n",
    "    # Hi√°nyz√≥ √©rt√©kek statisztik√°i\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percent = (missing_values / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({'Darabsz√°m': missing_values, 'Sz√°zal√©k': missing_percent})\n",
    "    missing_df = missing_df[missing_df['Darabsz√°m'] > 0].sort_values(by='Sz√°zal√©k', ascending=False)\n",
    "    \n",
    "    print(\"Hi√°nyz√≥ √©rt√©kek oszloponk√©nt:\")\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Hi√°nyz√≥ √©rt√©kek vizualiz√°ci√≥ja\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "    plt.title('Hi√°nyz√≥ √©rt√©kek eloszl√°sa a dokumentum metadatokban')\n",
    "    plt.show()\n",
    "    \n",
    "    # Kritikus hi√°nyz√≥ √©rt√©kek\n",
    "    critical_missing = missing_df[missing_df['Sz√°zal√©k'] > 50]  # 50% feletti hi√°ny\n",
    "    if not critical_missing.empty:\n",
    "        print(f\"‚ö†Ô∏è Kritikus hi√°nyz√≥ √©rt√©kek (>50%): {len(critical_missing)} oszlop\")\n",
    "        display(critical_missing)\n",
    "    else:\n",
    "        print(\"‚úÖ Nincsenek kritikus hi√°nyz√≥ √©rt√©kek\")\n",
    "else:\n",
    "    print(\"‚ùå Nincs adat a hi√°nyz√≥ √©rt√©kek elemz√©s√©hez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "categorical-analysis",
   "metadata": {},
   "source": [
    "## 4. Kategorikus V√°ltoz√≥k Elemz√©se\n",
    "\n",
    "A b√≠r√≥s√°gok, jogter√ºletek √©s egy√©b kategorikus v√°ltoz√≥k elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-categorical-vars",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_categories(df, column_name, top_n=20):\n",
    "    \"\"\"Seg√©df√ºggv√©ny a leggyakoribb kateg√≥ri√°k megjelen√≠t√©s√©re.\"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"‚ùå '{column_name}' oszlop nem tal√°lhat√≥\")\n",
    "        return\n",
    "    \n",
    "    counts = df[column_name].value_counts()\n",
    "    print(f\"\\n'{column_name}' egyedi √©rt√©keinek sz√°ma: {counts.nunique()}\")\n",
    "    print(f\"Leggyakoribb {top_n} √©rt√©k:\")\n",
    "    display(counts.head(top_n))\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    counts.head(top_n).plot(kind='bar')\n",
    "    plt.title(f'Dokumentumok megoszl√°sa - {column_name} (Top {top_n})')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel('Dokumentumok sz√°ma')\n",
    "    plt.xticks(rotation=75, ha='right')\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    print(\"üìä Kategorikus v√°ltoz√≥k elemz√©se:\")\n",
    "    \n",
    "    # B√≠r√≥s√°g elemz√©se\n",
    "    if 'birosag' in df.columns:\n",
    "        plot_top_categories(df, 'birosag', top_n=30)\n",
    "    \n",
    "    # Jogter√ºlet elemz√©se\n",
    "    if 'JogTerulet' in df.columns:\n",
    "        plot_top_categories(df, 'JogTerulet', top_n=20)\n",
    "    \n",
    "    # Egy√©b fontos kategorikus v√°ltoz√≥k\n",
    "    for col in ['MeghozoBirosag', 'Kollegium', 'AllKapcsolodoBirosag']:\n",
    "        if col in df.columns:\n",
    "            plot_top_categories(df, col, top_n=15)\n",
    "else:\n",
    "    print(\"‚ùå Nincs adat a kategorikus v√°ltoz√≥k elemz√©s√©hez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "time-analysis",
   "metadata": {},
   "source": [
    "## 5. Id≈ëbeli Elemz√©s\n",
    "\n",
    "A hat√°rozatok id≈ëbeli eloszl√°s√°nak elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-time-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty and 'HatarozatEve' in df.columns:\n",
    "    print(\"üìÖ Id≈ëbeli elemz√©s:\")\n",
    "    \n",
    "    # √âvsz√°mok tiszt√≠t√°sa\n",
    "    df['HatarozatEve_clean'] = pd.to_numeric(df['HatarozatEve'], errors='coerce').astype('Int64')\n",
    "    valid_years_mask = (df['HatarozatEve_clean'] >= 2005) & (df['HatarozatEve_clean'] <= pd.Timestamp.now().year)\n",
    "    valid_years = df.loc[valid_years_mask, 'HatarozatEve_clean']\n",
    "    \n",
    "    print(f\"√ârv√©nyes 'HatarozatEve' √©rt√©kek sz√°ma (2005 √≥ta): {len(valid_years)}\")\n",
    "    print(f\"√ârv√©nytelen vagy hi√°nyz√≥ 'HatarozatEve' √©rt√©kek sz√°ma: {len(df) - len(valid_years)}\")\n",
    "    \n",
    "    if not valid_years.empty:\n",
    "        # √âves eloszl√°s\n",
    "        year_counts = valid_years.value_counts().sort_index()\n",
    "        print(f\"\\n√âvek tartom√°ny: {year_counts.index.min()} - {year_counts.index.max()}\")\n",
    "        \n",
    "        plt.figure(figsize=(15, 7))\n",
    "        year_counts.plot(kind='line', marker='o', linewidth=2)\n",
    "        plt.title('Dokumentumok megoszl√°sa hat√°rozat √©ve szerint (2005 √≥ta)')\n",
    "        plt.xlabel('Hat√°rozat √âve')\n",
    "        plt.ylabel('Dokumentumok sz√°ma')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.fill_between(year_counts.index, year_counts.values, alpha=0.1)\n",
    "        plt.show()\n",
    "        \n",
    "        # Top √©vek t√°bl√°zata\n",
    "        print(\"\\nTop 10 √©v dokumentum sz√°m szerint:\")\n",
    "        top_years = year_counts.nlargest(10)\n",
    "        display(top_years.to_frame('Dokumentumok sz√°ma'))\n",
    "    else:\n",
    "        print(\"‚ùå Nincsenek √©rv√©nyes √©vsz√°mok 2005 √≥ta\")\n",
    "else:\n",
    "    print(\"‚ùå Nincs 'HatarozatEve' oszlop vagy adat az id≈ëbeli elemz√©shez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correlation-analysis",
   "metadata": {},
   "source": [
    "## 6. B√≠r√≥s√°g √©s Jogter√ºlet Kapcsolata\n",
    "\n",
    "A b√≠r√≥s√°gok √©s jogter√ºletek k√∂z√∂tti kapcsolat elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-court-domain-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty and 'birosag' in df.columns and 'JogTerulet' in df.columns:\n",
    "    print(\"üîó B√≠r√≥s√°g √©s jogter√ºlet kapcsolata:\")\n",
    "    \n",
    "    # Top b√≠r√≥s√°gok √©s jogter√ºletek kiv√°laszt√°sa\n",
    "    top_n_birosag = 20\n",
    "    top_m_jogterulet = 15\n",
    "    top_birosagok = df['birosag'].value_counts().nlargest(top_n_birosag).index\n",
    "    top_jogteruletek = df['JogTerulet'].value_counts().nlargest(top_m_jogterulet).index\n",
    "    \n",
    "    # Sz≈±rt adatkeret\n",
    "    df_filtered = df[df['birosag'].isin(top_birosagok) & df['JogTerulet'].isin(top_jogteruletek)]\n",
    "    print(f\"Sz≈±rt adatok: {len(df_filtered)} dokumentum\")\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Keresztt√°bla l√©trehoz√°sa\n",
    "        crosstab_bj = pd.crosstab(df_filtered['birosag'], df_filtered['JogTerulet'])\n",
    "        \n",
    "        # Heatmap\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.heatmap(crosstab_bj, cmap=\"viridis\", annot=False, fmt=\"d\", cbar_kws={'label': 'Dokumentumok sz√°ma'})\n",
    "        plt.title(f'B√≠r√≥s√°gok √©s jogter√ºletek kapcsolata (Top {top_n_birosag} b√≠r√≥s√°g, Top {top_m_jogterulet} jogter√ºlet)')\n",
    "        plt.xlabel('Jogter√ºlet')\n",
    "        plt.ylabel('B√≠r√≥s√°g')\n",
    "        plt.xticks(rotation=60, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Legnagyobb kapcsolatok\n",
    "        print(\"\\nTop 20 b√≠r√≥s√°g-jogter√ºlet kapcsolat:\")\n",
    "        top_relations = crosstab_bj.stack().nlargest(20)\n",
    "        display(top_relations.to_frame('Dokumentumok sz√°ma'))\n",
    "    else:\n",
    "        print(\"‚ùå Nem tal√°lhat√≥ el√©g adat a sz≈±rt b√≠r√≥s√°gokhoz √©s jogter√ºletekhez\")\n",
    "else:\n",
    "    print(\"‚ùå Hi√°nyz√≥ oszlopok ('birosag' vagy 'JogTerulet') a kapcsolat elemz√©s√©hez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chunk-count-analysis",
   "metadata": {},
   "source": [
    "## 7. Chunk Sz√°mok Elemz√©se\n",
    "\n",
    "A dokumentumokhoz tartoz√≥ chunk sz√°mok elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-chunk-counts",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty and 'chunk_count' in df.columns:\n",
    "    print(\"üìÑ Chunk sz√°mok elemz√©se:\")\n",
    "    \n",
    "    chunk_stats = df['chunk_count'].describe()\n",
    "    print(\"Chunk sz√°mok statisztik√°i:\")\n",
    "    display(chunk_stats)\n",
    "    \n",
    "    # Chunk sz√°m eloszl√°s\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(x=df['chunk_count'], bins=50, kde=True)\n",
    "    plt.title('Chunk sz√°mok eloszl√°sa dokumentumonk√©nt')\n",
    "    plt.xlabel('Chunkok sz√°ma')\n",
    "    plt.ylabel('Dokumentumok sz√°ma')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(y=df['chunk_count'])\n",
    "    plt.title('Chunk sz√°mok boxplot')\n",
    "    plt.ylabel('Chunkok sz√°ma')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Kiugr√≥ √©rt√©kek\n",
    "    q1, q3 = chunk_stats['25%'], chunk_stats['75%']\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = df[df['chunk_count'] > upper_bound]\n",
    "    \n",
    "    print(f\"\\nKiugr√≥ √©rt√©kek (> {upper_bound:.1f} chunk): {len(outliers)} dokumentum\")\n",
    "    if len(outliers) > 0:\n",
    "        print(\"Top 10 kiugr√≥ √©rt√©k:\")\n",
    "        display(outliers[['doc_id', 'chunk_count']].nlargest(10, 'chunk_count'))\n",
    "    \n",
    "    # Chunk sz√°m √©s √©v kapcsolata\n",
    "    if 'HatarozatEve_clean' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        valid_data = df.dropna(subset=['chunk_count', 'HatarozatEve_clean'])\n",
    "        if len(valid_data) > 100:\n",
    "            plt.scatter(valid_data['HatarozatEve_clean'], valid_data['chunk_count'], alpha=0.5)\n",
    "            plt.title('Chunk sz√°mok alakul√°sa az √©vek sor√°n')\n",
    "            plt.xlabel('Hat√°rozat √©ve')\n",
    "            plt.ylabel('Chunkok sz√°ma')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"‚ùå Nincs 'chunk_count' oszlop a chunk sz√°mok elemz√©s√©hez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identifier-analysis",
   "metadata": {},
   "source": [
    "## 8. Azonos√≠t√≥k Elemz√©se\n",
    "\n",
    "A k√ºl√∂nb√∂z≈ë azonos√≠t√≥k (doc_id, Azonosito, EgyediAzonosito) elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-identifiers",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"üÜî Azonos√≠t√≥k elemz√©se:\")\n",
    "    \n",
    "    for id_col in ['doc_id', 'Azonosito', 'EgyediAzonosito']:\n",
    "        if id_col in df.columns:\n",
    "            print(f\"\\nüîç '{id_col}' elemz√©se:\")\n",
    "            uniqueness = df[id_col].nunique()\n",
    "            total_rows = len(df)\n",
    "            duplicates = total_rows - uniqueness\n",
    "            \n",
    "            print(f\"  √ñsszes dokumentum: {total_rows}\")\n",
    "            print(f\"  Egyedi √©rt√©kek: {uniqueness}\")\n",
    "            print(f\"  Duplik√°lt/hi√°nyz√≥ √©rt√©kek: {duplicates}\")\n",
    "            print(f\"  Unikalit√°s ar√°nya: {100 * uniqueness / total_rows:.2f}%\")\n",
    "            \n",
    "            if duplicates > 0:\n",
    "                duplicated_ids = df[df.duplicated(subset=[id_col], keep=False)][id_col].value_counts()\n",
    "                print(f\"  Leggyakoribb duplik√°lt '{id_col}' √©rt√©kek:\")\n",
    "                display(duplicated_ids[duplicated_ids > 1].head())\n",
    "            \n",
    "            # Mintav√©tel egyedi √©rt√©kekb≈ël\n",
    "            print(f\"  '{id_col}' √©rt√©kek mint√°i:\")\n",
    "            sample_ids = df[id_col].dropna().sample(min(5, uniqueness)).tolist()\n",
    "            for i, sample_id in enumerate(sample_ids):\n",
    "                print(f\"    {i+1}. {sample_id}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è '{id_col}' oszlop nem tal√°lhat√≥\")\n",
    "else:\n",
    "    print(\"‚ùå Nincs adat az azonos√≠t√≥k elemz√©s√©hez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-references-analysis",
   "metadata": {},
   "source": [
    "## 9. Jogszab√°lyhelyek M√©lyebb Elemz√©se\n",
    "\n",
    "A jogszab√°lyi hivatkoz√°sok elemz√©se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-legal-references",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty and 'Jogszabalyhelyek' in df.columns:\n",
    "    print(\"‚öñÔ∏è Jogszab√°lyhelyek elemz√©se:\")\n",
    "    \n",
    "    # Diagnosztika\n",
    "    print(\"\\nDiagnosztika: Jogszabalyhelyek minta:\")\n",
    "    sample_values = df['Jogszabalyhelyek'].dropna().head(5)\n",
    "    for i, val in enumerate(sample_values):\n",
    "        print(f\"  {i+1}: Type={type(val)}, Value='{str(val)[:100]}...'\")\n",
    "    \n",
    "    # Jogszab√°lyhelyek feldolgoz√°sa\n",
    "    def parse_jogszabaly(value):\n",
    "        if pd.isna(value) or not isinstance(value, str) or value.strip() == '[]' or not value.strip():\n",
    "            return []\n",
    "        try:\n",
    "            # Egyszer≈± darabol√°s a '</br>' ment√©n\n",
    "            items = value.split('</br>')\n",
    "            # √úres elemek kisz≈±r√©se √©s sz√≥k√∂z√∂k elt√°vol√≠t√°sa\n",
    "            cleaned_items = [item.strip() for item in items if item.strip()]\n",
    "            return cleaned_items\n",
    "        except Exception as e:\n",
    "            print(f\"Hiba a jogszab√°lyhely feldolgoz√°sa k√∂zben: {e}\")\n",
    "            return []\n",
    "    \n",
    "    df['parsed_jogszabalyhelyek'] = df['Jogszabalyhelyek'].apply(parse_jogszabaly)\n",
    "    jogszabaly_series = df['parsed_jogszabalyhelyek'].explode().dropna()\n",
    "    \n",
    "    print(f\"\\n√ñsszesen {len(jogszabaly_series)} jogszab√°lyhely hivatkoz√°s tal√°lhat√≥\")\n",
    "    print(f\"Dokumentumok jogszab√°lyhellyel: {df['parsed_jogszabalyhelyek'].apply(len).gt(0).sum()}/{len(df)}\")\n",
    "    \n",
    "    if not jogszabaly_series.empty:\n",
    "        jogszabaly_counts = jogszabaly_series.value_counts()\n",
    "        print(f\"\\nEgyedi jogszab√°lyhelyek sz√°ma: {len(jogszabaly_counts)}\")\n",
    "        \n",
    "        # Top jogszab√°lyhelyek\n",
    "        top_n = 30\n",
    "        print(f\"\\nLeggyakrabban hivatkozott {top_n} jogszab√°lyhely:\")\n",
    "        display(jogszabaly_counts.head(top_n).to_frame('Hivatkoz√°sok sz√°ma'))\n",
    "        \n",
    "        # Vizualiz√°ci√≥\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        jogszabaly_counts.head(top_n).plot(kind='barh')\n",
    "        plt.title(f'Leggyakrabban hivatkozott {top_n} jogszab√°lyhely')\n",
    "        plt.xlabel('Hivatkoz√°sok sz√°ma')\n",
    "        plt.ylabel('Jogszab√°lyhely')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Jogszab√°ly t√≠pus szerinti csoportos√≠t√°s\n",
    "        def get_law_type(jogszabaly):\n",
    "            if 't√∂rv√©ny' in jogszabaly.lower() or 'tv.' in jogszabaly.lower():\n",
    "                return 'T√∂rv√©ny'\n",
    "            elif 'rendelet' in jogszabaly.lower() or 'korm.' in jogszabaly.lower():\n",
    "                return 'Rendelet'\n",
    "            elif 'pk' in jogszabaly.lower() or 'polg√°ri' in jogszabaly.lower():\n",
    "                return 'Polg√°ri t√∂rv√©nyk√∂nyv'\n",
    "            elif 'btk' in jogszabaly.lower() or 'b√ºntet≈ë' in jogszabaly.lower():\n",
    "                return 'B√ºntet≈ë t√∂rv√©nyk√∂nyv'\n",
    "            else:\n",
    "                return 'Egy√©b'\n",
    "        \n",
    "        jogszabaly_types = jogszabaly_series.apply(get_law_type)\n",
    "        type_counts = jogszabaly_types.value_counts()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        type_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('Jogszab√°ly t√≠pusok megoszl√°sa')\n",
    "        plt.ylabel('')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ùå Nem tal√°lhat√≥ √©rv√©nyes jogszab√°lyhely hivatkoz√°s\")\n",
    "else:\n",
    "    print(\"‚ùå Nincs 'Jogszabalyhelyek' oszlop a jogszab√°lyhelyek elemz√©s√©hez\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "## 10. K√∂vetkeztet√©sek\n",
    "\n",
    "A dokumentum metadatok ki√©rt√©kel√©s√©nek √∂sszefoglal√°sa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-conclusions",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DOKUMENTUM METADATOK ELEMZ√âS √ñSSZEFOGLAL√ì ===\")\n",
    "print(\"\\n‚úÖ Sikeresen elemezve:\")\n",
    "if df is not None:\n",
    "    print(f\"   üìÑ Dokumentumok: {len(df)} db\")\n",
    "    print(f\"   üìä Oszlopok: {len(df.columns)} db\")\n",
    "    \n",
    "    # Hi√°nyz√≥ √©rt√©kek √∂sszes√≠t√©se\n",
    "    missing_total = df.isnull().sum().sum()\n",
    "    total_cells = df.shape[0] * df.shape[1]\n",
    "    missing_ratio = missing_total / total_cells * 100\n",
    "    print(f\"   ‚ùå Hi√°nyz√≥ √©rt√©kek: {missing_total}/{total_cells} ({missing_ratio:.2f}%)\")\n",
    "    \n",
    "    # Unikalit√°s ellen≈ërz√©se\n",
    "    unique_doc_ids = df['doc_id'].nunique() if 'doc_id' in df.columns else 0\n",
    "    print(f\"   üÜî Egyedi doc_id: {unique_doc_ids}/{len(df)} ({100 * unique_doc_ids / len(df):.2f}%)\")\n",
    "\n",
    "print(\"\\nüìã Agents.md specifik√°ci√≥ ellen≈ërz√©s:\")\n",
    "if df is not None:\n",
    "    # Alapvet≈ë metadatok megl√©te\n",
    "    required_cols = ['doc_id', 'raw_path', 'chunk_count']\n",
    "    missing_required = [col for col in required_cols if col not in df.columns]\n",
    "    if not missing_required:\n",
    "        print(\"   ‚úÖ Alapvet≈ë metadatok jelen vannak\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Hi√°nyz√≥ alapvet≈ë metadatok: {missing_required}\")\n",
    "    \n",
    "    # Id≈ëbeli adatok\n",
    "    if 'HatarozatEve' in df.columns:\n",
    "        valid_years = pd.to_numeric(df['HatarozatEve'], errors='coerce').notna().sum()\n",
    "        print(f\"   üìÖ √ârv√©nyes √©vsz√°mok: {valid_years}/{len(df)} ({100 * valid_years / len(df):.2f}%)\")\n",
    "    \n",
    "    # Jogter√ºletek\n",
    "    if 'JogTerulet' in df.columns:\n",
    "        valid_domains = df['JogTerulet'].notna().sum()\n",
    "        print(f\"   ‚öñÔ∏è √ârv√©nyes jogter√ºletek: {valid_domains}/{len(df)} ({100 * valid_domains / len(df):.2f}%)\")\n",
    "\n",
    "print(\"\\nüí° Aj√°nl√°sok:\")\n",
    "if df is not None:\n",
    "    # Kritikus hi√°nyz√≥ √©rt√©kek\n",
    "    critical_missing = df.isnull().sum()\n",
    "    critical_cols = critical_missing[critical_missing > len(df) * 0.5]  # 50% feletti hi√°ny\n",
    "    if len(critical_cols) > 0:\n",
    "        print(f\"   üîß Kritikus hi√°nyz√≥ √©rt√©kek jav√≠t√°sa: {list(critical_cols.index)}\")\n",
    "    \n",
    "    # Duplik√°lt azonos√≠t√≥k\n",
    "    if 'doc_id' in df.columns:\n",
    "        duplicates = len(df) - df['doc_id'].nunique()\n",
    "        if duplicates > 0:\n",
    "            print(f\"   üÜî Duplik√°lt doc_id-k jav√≠t√°sa: {duplicates} db\")\n",
    "    \n",
    "    # Hi√°nyz√≥ chunk sz√°mok\n",
    "    if 'chunk_count' not in df.columns:\n",
    "        print(\"   üìù Chunk sz√°mok hozz√°ad√°sa sz√ºks√©ges\")\n",
    "\n",
    "print(\"\\nüéØ Metadatok elemz√©se k√©sz - a retrieval rendszer haszn√°latra k√©sz!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
