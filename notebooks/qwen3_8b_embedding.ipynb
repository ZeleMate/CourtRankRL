{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Magyar Bírósági Határozatok - Embedding Generálás\n",
        "\n",
        "**Qwen/Qwen3-Embedding-8B modell használata A100 80GB GPU-n**\n",
        "\n",
        "---\n",
        "\n",
        "## Projekt Információk\n",
        "\n",
        "- **Embedding Modell**: Qwen/Qwen3-Embedding-8B\n",
        "- **Embedding Dimenzió**: 8192\n",
        "- **Ajánlott Hardver**: A100 80GB GPU (RunPod/Vast.ai)\n",
        "- **Becsült Futásidő**: 2-3 óra (~213k dokumentum)\n",
        "- **Kimeneti Formátum**: Parquet (8192 dimenziós embedding vektorok)\n",
        "- **Optimalizációk**: Mixed precision, adaptív batch sizing, memória monitoring\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Könyvtárak telepítése\n",
        "!pip install -U torch sentence-transformers accelerate pyarrow pandas tqdm transformers\n",
        "print(\"Könyvtárak telepítve\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Qwen3-Embedding-8B Script - Optimalizált konfiguráció\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import json\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import psutil\n",
        "import time\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Any\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================\n",
        "# OPTIMALIZÁLT KONFIGURÁLÁS - A100 80GB\n",
        "# ============================================================\n",
        "\n",
        "# Fájl elérési utak\n",
        "INPUT_CSV = \"cleaned_data_for_embedding.csv\"\n",
        "OUTPUT_PARQUET = \"processed_documents_with_embeddings.parquet\"\n",
        "MODEL_NAME = \"Qwen/Qwen3-Embedding-8B\"\n",
        "\n",
        "# A100 80GB optimalizált paraméterek\n",
        "CHUNKSIZE = 10000          # Nagyobb chunk méret GPU-ra\n",
        "BATCH_SIZE = 32            # Optimális batch méret A100-ra\n",
        "MAX_TOKEN_LENGTH = 8192    # Qwen3-8B max context\n",
        "PREFETCH_FACTOR = 4        # DataLoader prefetch\n",
        "NUM_WORKERS = 8            # Párhuzamos adatbetöltés\n",
        "\n",
        "# Fejlett GPU optimalizáció\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = False\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# Mixed precision beállítások\n",
        "USE_MIXED_PRECISION = True\n",
        "AUTOCAST_ENABLED = True\n",
        "\n",
        "# Memória optimalizáció\n",
        "MEMORY_LIMIT_GB = 75       # A100 80GB-ból 75GB használata\n",
        "GRADIENT_CHECKPOINTING = True\n",
        "\n",
        "# Logging konfigurálás\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, \n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(),\n",
        "        logging.FileHandler('embedding_generation.log')\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"Optimalizált Qwen3-Embedding-8B Generátor\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Modell: {MODEL_NAME}\")\n",
        "print(f\"Dimenzió: 8192\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Chunk Size: {CHUNKSIZE:,}\")\n",
        "print(f\"Memória limit: {MEMORY_LIMIT_GB}GB\")\n",
        "print(f\"Mixed Precision: {USE_MIXED_PRECISION}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Segédfüggvények\n",
        "def get_system_info():\n",
        "    \"\"\"Rendszerinformációk lekérdezése.\"\"\"\n",
        "    info = {\n",
        "        'total_memory_gb': psutil.virtual_memory().total / (1024**3),\n",
        "        'available_memory_gb': psutil.virtual_memory().available / (1024**3),\n",
        "        'cpu_count': psutil.cpu_count(),\n",
        "        'gpu_available': torch.cuda.is_available(),\n",
        "        'gpu_count': torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
        "    }\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        info['gpu_name'] = torch.cuda.get_device_name(0)\n",
        "        info['gpu_memory_gb'] = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "    \n",
        "    return info\n",
        "\n",
        "def adaptive_batch_size(text_lengths: List[int], base_batch_size: int = BATCH_SIZE) -> int:\n",
        "    \"\"\"Adaptív batch méret szöveg hossz alapján.\"\"\"\n",
        "    avg_length = np.mean(text_lengths)\n",
        "    \n",
        "    if avg_length > 6000:\n",
        "        return max(8, base_batch_size // 4)\n",
        "    elif avg_length > 4000:\n",
        "        return max(16, base_batch_size // 2)\n",
        "    elif avg_length > 2000:\n",
        "        return base_batch_size\n",
        "    else:\n",
        "        return min(64, base_batch_size * 2)\n",
        "\n",
        "def smart_memory_cleanup():\n",
        "    \"\"\"Intelligens memóriakezelés.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "    gc.collect()\n",
        "    \n",
        "def estimate_processing_time(total_texts: int, batch_size: int, avg_time_per_batch: float) -> Dict[str, float]:\n",
        "    \"\"\"Becsült feldolgozási idő kalkuláció.\"\"\"\n",
        "    total_batches = (total_texts + batch_size - 1) // batch_size\n",
        "    estimated_seconds = total_batches * avg_time_per_batch\n",
        "    \n",
        "    return {\n",
        "        'total_batches': total_batches,\n",
        "        'estimated_hours': estimated_seconds / 3600,\n",
        "        'estimated_minutes': estimated_seconds / 60\n",
        "    }\n",
        "\n",
        "def create_metadata_json(row: pd.Series) -> str:\n",
        "    \"\"\"Optimalizált metadata JSON generálás.\"\"\"\n",
        "    metadata = {\n",
        "        'doc_id': str(row.get('doc_id', '')),\n",
        "        'birosag': str(row.get('birosag', '')),\n",
        "        'jogterulet': str(row.get('jogterulet', '')),\n",
        "        'hatarozat_id_mappa': str(row.get('hatarozat_id_mappa', '')),\n",
        "        'text_length': len(str(row.get('text', ''))),\n",
        "        'processed_timestamp': time.time()\n",
        "    }\n",
        "    return json.dumps(metadata, ensure_ascii=False)\n",
        "\n",
        "# Rendszerinformációk megjelenítése\n",
        "sys_info = get_system_info()\n",
        "print(\"Rendszer információk:\")\n",
        "print(\"=\" * 40)\n",
        "for key, value in sys_info.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "print(\"=\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Optimalizált Qwen3-8B Embedding Osztály\n",
        "class OptimizedQwen3EmbeddingGenerator:\n",
        "    \"\"\"\n",
        "    Optimalizált Qwen3-Embedding-8B implementáció A100 80GB GPU-ra.\n",
        "    \n",
        "    Főbb optimalizációk:\n",
        "    - Mixed precision training (AMP)\n",
        "    - Adaptív batch sizing\n",
        "    - Memória monitoring és cleanup\n",
        "    - Fejlett progress tracking\n",
        "    - Chunk-based processing\n",
        "    - Dynamic GPU memory management\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model_name = MODEL_NAME\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.dimension = 8192\n",
        "        self.max_tokens = MAX_TOKEN_LENGTH\n",
        "        \n",
        "        # Performance tracking\n",
        "        self.processed_count = 0\n",
        "        self.failed_count = 0\n",
        "        self.total_processing_time = 0\n",
        "        self.batch_times = []\n",
        "        \n",
        "        # Memory monitoring\n",
        "        self.peak_memory_usage = 0\n",
        "        self.memory_warnings = 0\n",
        "        \n",
        "        logger.info(f\"Optimalizált generátor inicializálása...\")\n",
        "        logger.info(f\"Device: {self.device}\")\n",
        "        \n",
        "        try:\n",
        "            # Model loading with optimizations\n",
        "            logger.info(f\"Qwen3-Embedding-8B betöltése...\")\n",
        "            \n",
        "            self.model = SentenceTransformer(\n",
        "                self.model_name,\n",
        "                device=self.device,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            \n",
        "            # Model optimalizálás\n",
        "            if self.device == 'cuda':\n",
        "                self.model.half() if USE_MIXED_PRECISION else None\n",
        "                \n",
        "            # Warmup\n",
        "            self._warmup_model()\n",
        "            \n",
        "            logger.info(f\"Modell sikeresen betöltve és optimalizálva\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Modell betöltési hiba: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def _warmup_model(self):\n",
        "        \"\"\"Modell warmup a konzisztens teljesítményért.\"\"\"\n",
        "        logger.info(\"Modell warmup...\")\n",
        "        dummy_text = [\"Ez egy teszt szöveg a modell bemelegítéséhez.\"] * 4\n",
        "        \n",
        "        with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and AUTOCAST_ENABLED):\n",
        "            _ = self.model.encode(dummy_text, show_progress_bar=False)\n",
        "        \n",
        "        smart_memory_cleanup()\n",
        "        logger.info(\"Warmup befejezve\")\n",
        "    \n",
        "    def _monitor_memory(self) -> Dict[str, float]:\n",
        "        \"\"\"GPU memória monitoring.\"\"\"\n",
        "        if not torch.cuda.is_available():\n",
        "            return {}\n",
        "        \n",
        "        allocated = torch.cuda.memory_allocated() / (1024**3)\n",
        "        reserved = torch.cuda.memory_reserved() / (1024**3)\n",
        "        max_allocated = torch.cuda.max_memory_allocated() / (1024**3)\n",
        "        \n",
        "        self.peak_memory_usage = max(self.peak_memory_usage, allocated)\n",
        "        \n",
        "        # Memory warning\n",
        "        if allocated > MEMORY_LIMIT_GB * 0.9:\n",
        "            self.memory_warnings += 1\n",
        "            logger.warning(f\"Magas memóriahasználat: {allocated:.1f}GB\")\n",
        "        \n",
        "        return {\n",
        "            'allocated_gb': allocated,\n",
        "            'reserved_gb': reserved,\n",
        "            'max_allocated_gb': max_allocated,\n",
        "            'peak_usage_gb': self.peak_memory_usage\n",
        "        }\n",
        "    \n",
        "    def _process_batch_with_optimization(self, batch_texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Optimalizált batch feldolgozás mixed precision-nel.\"\"\"\n",
        "        batch_start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            # Szöveg előfeldolgozás\n",
        "            processed_texts = []\n",
        "            for text in batch_texts:\n",
        "                if len(text) > self.max_tokens * 3:  # ~3 char/token\n",
        "                    text = text[:self.max_tokens * 3]\n",
        "                processed_texts.append(text)\n",
        "            \n",
        "            # Mixed precision embedding generálás\n",
        "            with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and AUTOCAST_ENABLED):\n",
        "                embeddings = self.model.encode(\n",
        "                    processed_texts,\n",
        "                    normalize_embeddings=True,\n",
        "                    show_progress_bar=False,\n",
        "                    convert_to_numpy=True,\n",
        "                    batch_size=len(processed_texts)\n",
        "                )\n",
        "            \n",
        "            # Dimenzió ellenőrzés és korrekció\n",
        "            if embeddings.shape[1] != self.dimension:\n",
        "                if embeddings.shape[1] > self.dimension:\n",
        "                    embeddings = embeddings[:, :self.dimension]\n",
        "                else:\n",
        "                    padding = np.zeros((embeddings.shape[0], self.dimension - embeddings.shape[1]))\n",
        "                    embeddings = np.hstack([embeddings, padding])\n",
        "            \n",
        "            # Performance tracking\n",
        "            batch_time = time.time() - batch_start_time\n",
        "            self.batch_times.append(batch_time)\n",
        "            self.processed_count += len(batch_texts)\n",
        "            \n",
        "            return embeddings.astype(np.float32)\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Batch feldolgozási hiba: {e}\")\n",
        "            self.failed_count += len(batch_texts)\n",
        "            # Fallback: NaN vektorok\n",
        "            return np.full((len(batch_texts), self.dimension), np.nan, dtype=np.float32)\n",
        "        \n",
        "        finally:\n",
        "            # Memória cleanup minden batch után\n",
        "            if self.processed_count % 100 == 0:\n",
        "                smart_memory_cleanup()\n",
        "    \n",
        "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Optimalizált embedding generálás.\"\"\"\n",
        "        total_texts = len(texts)\n",
        "        logger.info(f\"Optimalizált embedding generálás {total_texts:,} szöveghez\")\n",
        "        \n",
        "        if not texts:\n",
        "            return np.array([])\n",
        "        \n",
        "        # Text length analysis for adaptive batching\n",
        "        text_lengths = [len(text) for text in texts]\n",
        "        dynamic_batch_size = adaptive_batch_size(text_lengths, BATCH_SIZE)\n",
        "        \n",
        "        logger.info(f\"Adaptív batch méret: {dynamic_batch_size}\")\n",
        "        logger.info(f\"Átlagos szöveghossz: {np.mean(text_lengths):.0f} karakter\")\n",
        "        \n",
        "        all_embeddings = []\n",
        "        total_batches = (total_texts + dynamic_batch_size - 1) // dynamic_batch_size\n",
        "        \n",
        "        # Enhanced progress bar\n",
        "        with tqdm(\n",
        "            total=total_batches, \n",
        "            desc=\"Embedding generálás\", \n",
        "            unit=\"batch\",\n",
        "            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'\n",
        "        ) as pbar:\n",
        "            \n",
        "            for i in range(0, total_texts, dynamic_batch_size):\n",
        "                batch_texts = texts[i:i + dynamic_batch_size]\n",
        "                \n",
        "                # Memory monitoring\n",
        "                memory_info = self._monitor_memory()\n",
        "                \n",
        "                # Batch processing\n",
        "                batch_embeddings = self._process_batch_with_optimization(batch_texts)\n",
        "                all_embeddings.extend(batch_embeddings.tolist())\n",
        "                \n",
        "                # Progress update with performance metrics\n",
        "                if self.batch_times:\n",
        "                    avg_batch_time = np.mean(self.batch_times[-10:])  # Last 10 batches\n",
        "                    texts_per_second = dynamic_batch_size / avg_batch_time\n",
        "                    \n",
        "                    pbar.set_postfix({\n",
        "                        'TPS': f'{texts_per_second:.1f}',\n",
        "                        'Mem': f'{memory_info.get(\"allocated_gb\", 0):.1f}GB',\n",
        "                        'Fail': self.failed_count\n",
        "                    })\n",
        "                \n",
        "                pbar.update(1)\n",
        "                \n",
        "                # Adaptive memory cleanup\n",
        "                if memory_info.get('allocated_gb', 0) > MEMORY_LIMIT_GB * 0.8:\n",
        "                    smart_memory_cleanup()\n",
        "        \n",
        "        # Final statistics\n",
        "        total_time = sum(self.batch_times)\n",
        "        self.total_processing_time = total_time\n",
        "        \n",
        "        logger.info(f\"Optimalizált generálás befejezve!\")\n",
        "        logger.info(f\"Összesített statisztikák:\")\n",
        "        logger.info(f\"   - Feldolgozott: {self.processed_count:,}/{total_texts:,}\")\n",
        "        logger.info(f\"   - Sikertelen: {self.failed_count:,}\")\n",
        "        logger.info(f\"   - Teljes idő: {total_time/3600:.2f} óra\")\n",
        "        logger.info(f\"   - Átlag sebesség: {self.processed_count/total_time:.1f} szöveg/sec\")\n",
        "        logger.info(f\"   - Csúcs memória: {self.peak_memory_usage:.1f}GB\")\n",
        "        \n",
        "        return np.array(all_embeddings, dtype=np.float32)\n",
        "\n",
        "# Embedding generátor inicializálása\n",
        "logger.info(\"Optimalizált Qwen3-8B generátor létrehozása...\")\n",
        "embedding_generator = OptimizedQwen3EmbeddingGenerator()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Főfolyamat - Optimalizált Chunk-alapú Feldolgozás\n",
        "def process_embeddings_optimized():\n",
        "    \"\"\"\n",
        "    Optimalizált embedding feldolgozás nagy adathalmazokhoz.\n",
        "    \n",
        "    Főbb optimalizációk:\n",
        "    - Chunk-alapú feldolgozás\n",
        "    - Streaming Parquet írás\n",
        "    - Memory-mapped file handling\n",
        "    - Adaptív batch sizing\n",
        "    - Real-time performance monitoring\n",
        "    \"\"\"\n",
        "    \n",
        "    start_time = time.time()\n",
        "    logger.info(\"Optimalizált embedding feldolgozás kezdése...\")\n",
        "    \n",
        "    # 1. Adatok betöltése és elemzése\n",
        "    logger.info(f\"CSV betöltése: {INPUT_CSV}\")\n",
        "    \n",
        "    try:\n",
        "        # Első betöltés a méret és struktúra ellenőrzéséhez\n",
        "        df_sample = pd.read_csv(INPUT_CSV, nrows=1000)\n",
        "        logger.info(f\"Sample betöltve: {len(df_sample)} sor\")\n",
        "        \n",
        "        # Teljes fájl méret becslése\n",
        "        total_rows = sum(1 for _ in open(INPUT_CSV, 'r', encoding='utf-8')) - 1  # -1 header\n",
        "        logger.info(f\"Becsült teljes sorok: {total_rows:,}\")\n",
        "        \n",
        "        # Oszlop ellenőrzés\n",
        "        required_columns = ['text', 'doc_id']\n",
        "        missing_columns = [col for col in required_columns if col not in df_sample.columns]\n",
        "        if missing_columns:\n",
        "            raise ValueError(f\"Hiányzó oszlopok: {missing_columns}\")\n",
        "        \n",
        "        logger.info(f\"Oszlop validáció sikeres\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Adatbetöltési hiba: {e}\")\n",
        "        raise\n",
        "    \n",
        "    # 2. Chunk-alapú feldolgozás optimalizálással\n",
        "    all_results = []\n",
        "    processed_rows = 0\n",
        "    chunk_number = 0\n",
        "    \n",
        "    # Performance tracking\n",
        "    chunk_times = []\n",
        "    memory_usage_log = []\n",
        "    \n",
        "    logger.info(f\"Chunk-alapú feldolgozás kezdése (chunk méret: {CHUNKSIZE:,})\")\n",
        "    \n",
        "    # Enhanced progress tracking\n",
        "    total_chunks = (total_rows + CHUNKSIZE - 1) // CHUNKSIZE\n",
        "    \n",
        "    with tqdm(total=total_chunks, desc=\"Chunk Processing\", unit=\"chunk\") as chunk_pbar:\n",
        "        \n",
        "        for chunk_df in pd.read_csv(INPUT_CSV, chunksize=CHUNKSIZE, encoding='utf-8'):\n",
        "            chunk_start_time = time.time()\n",
        "            chunk_number += 1\n",
        "            \n",
        "            logger.info(f\"Chunk {chunk_number}/{total_chunks} feldolgozása ({len(chunk_df):,} sor)\")\n",
        "            \n",
        "            try:\n",
        "                # Szöveg validáció és tisztítás\n",
        "                chunk_df = chunk_df.dropna(subset=['text', 'doc_id'])\n",
        "                chunk_df['text'] = chunk_df['text'].astype(str)\n",
        "                \n",
        "                valid_rows = len(chunk_df)\n",
        "                if valid_rows == 0:\n",
        "                    logger.warning(f\"Chunk {chunk_number}: nincs érvényes adat\")\n",
        "                    continue\n",
        "                \n",
        "                texts = chunk_df['text'].tolist()\n",
        "                \n",
        "                # Optimalizált embedding generálás\n",
        "                embeddings = embedding_generator.generate_embeddings(texts)\n",
        "                \n",
        "                # Eredmények hozzáadása a DataFrame-hez\n",
        "                chunk_df['embedding'] = embeddings.tolist()\n",
        "                \n",
        "                # Metadata JSON generálás optimalizáltan\n",
        "                chunk_df['metadata_json'] = chunk_df.apply(create_metadata_json, axis=1)\n",
        "                \n",
        "                # Memória optimalizáció: csak szükséges oszlopok\n",
        "                output_columns = ['doc_id', 'birosag', 'jogterulet', 'hatarozat_id_mappa', \n",
        "                                'text', 'embedding', 'metadata_json']\n",
        "                available_columns = [col for col in output_columns if col in chunk_df.columns]\n",
        "                chunk_df_output = chunk_df[available_columns].copy()\n",
        "                \n",
        "                all_results.append(chunk_df_output)\n",
        "                processed_rows += valid_rows\n",
        "                \n",
        "                # Performance metrics\n",
        "                chunk_time = time.time() - chunk_start_time\n",
        "                chunk_times.append(chunk_time)\n",
        "                \n",
        "                # Memory monitoring\n",
        "                current_memory = psutil.virtual_memory()\n",
        "                memory_usage_log.append({\n",
        "                    'chunk': chunk_number,\n",
        "                    'memory_used_gb': (current_memory.total - current_memory.available) / (1024**3),\n",
        "                    'memory_percent': current_memory.percent\n",
        "                })\n",
        "                \n",
        "                # Progress update with metrics\n",
        "                avg_chunk_time = np.mean(chunk_times[-5:])  # Last 5 chunks\n",
        "                rows_per_second = valid_rows / chunk_time\n",
        "                \n",
        "                chunk_pbar.set_postfix({\n",
        "                    'Rows/s': f'{rows_per_second:.1f}',\n",
        "                    'AvgTime': f'{avg_chunk_time:.1f}s',\n",
        "                    'Memory': f'{memory_usage_log[-1][\"memory_percent\"]:.1f}%',\n",
        "                    'Processed': f'{processed_rows:,}'\n",
        "                })\n",
        "                \n",
        "                chunk_pbar.update(1)\n",
        "                \n",
        "                # Memória kezelés nagy chunk-oknál\n",
        "                if chunk_number % 5 == 0:\n",
        "                    smart_memory_cleanup()\n",
        "                    logger.info(f\"Memória tisztítás chunk {chunk_number} után\")\n",
        "                \n",
        "                # ETA becslés\n",
        "                if len(chunk_times) >= 3:\n",
        "                    remaining_chunks = total_chunks - chunk_number\n",
        "                    estimated_remaining_time = remaining_chunks * avg_chunk_time\n",
        "                    logger.info(f\"Becsült hátralévő idő: {estimated_remaining_time/3600:.2f} óra\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                logger.error(f\"Chunk {chunk_number} feldolgozási hiba: {e}\")\n",
        "                continue\n",
        "    \n",
        "    # 3. Eredmények kombinálása és mentése\n",
        "    logger.info(\"Chunk-ok kombinálása...\")\n",
        "    \n",
        "    if not all_results:\n",
        "        raise ValueError(\"Nincs feldolgozott adat a mentéshez!\")\n",
        "    \n",
        "    try:\n",
        "        # Kombinálás memóriahatékony módon\n",
        "        final_df = pd.concat(all_results, ignore_index=True)\n",
        "        logger.info(f\"Kombinált DataFrame: {len(final_df):,} sor\")\n",
        "        \n",
        "        # Utolsó validáció\n",
        "        embedding_check = final_df['embedding'].apply(lambda x: len(x) == 8192 if isinstance(x, list) else False)\n",
        "        valid_embeddings = embedding_check.sum()\n",
        "        \n",
        "        logger.info(f\"Érvényes embeddingek: {valid_embeddings:,}/{len(final_df):,}\")\n",
        "        \n",
        "        # Parquet mentés optimalizáltan\n",
        "        logger.info(f\"Parquet mentés: {OUTPUT_PARQUET}\")\n",
        "        \n",
        "        final_df.to_parquet(\n",
        "            OUTPUT_PARQUET,\n",
        "            engine='pyarrow',\n",
        "            index=False,\n",
        "            compression='snappy'\n",
        "        )\n",
        "        \n",
        "        logger.info(f\"Parquet fájl sikeresen mentve\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Mentési hiba: {e}\")\n",
        "        raise\n",
        "    \n",
        "    # 4. Végső statisztikák\n",
        "    total_time = time.time() - start_time\n",
        "    \n",
        "    logger.info(\"OPTIMALIZÁLT FELDOLGOZÁS BEFEJEZVE!\")\n",
        "    logger.info(\"=\" * 60)\n",
        "    logger.info(f\"Végső statisztikák:\")\n",
        "    logger.info(f\"   Feldolgozott sorok: {processed_rows:,}\")\n",
        "    logger.info(f\"   Feldolgozott chunk-ok: {chunk_number}\")\n",
        "    logger.info(f\"   Teljes futásidő: {total_time/3600:.2f} óra\")\n",
        "    logger.info(f\"   Átlag feldolgozási sebesség: {processed_rows/total_time:.1f} sor/sec\")\n",
        "    logger.info(f\"   Kimeneti fájl: {OUTPUT_PARQUET}\")\n",
        "    logger.info(f\"   Embedding generátor statisztikák:\")\n",
        "    logger.info(f\"      - Sikeres: {embedding_generator.processed_count:,}\")\n",
        "    logger.info(f\"      - Sikertelen: {embedding_generator.failed_count:,}\")\n",
        "    logger.info(f\"      - Csúcs memória: {embedding_generator.peak_memory_usage:.1f}GB\")\n",
        "    logger.info(\"=\" * 60)\n",
        "    \n",
        "    return {\n",
        "        'processed_rows': processed_rows,\n",
        "        'total_time_hours': total_time / 3600,\n",
        "        'average_speed': processed_rows / total_time,\n",
        "        'output_file': OUTPUT_PARQUET,\n",
        "        'chunk_count': chunk_number,\n",
        "        'embedding_stats': {\n",
        "            'successful': embedding_generator.processed_count,\n",
        "            'failed': embedding_generator.failed_count,\n",
        "            'peak_memory_gb': embedding_generator.peak_memory_usage\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Főfolyamat indítása\n",
        "logger.info(\"Optimalizált főfolyamat indítása...\")\n",
        "results = process_embeddings_optimized()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Eredmények Validálása és Végső Statisztikák\n",
        "def validate_and_finalize_results():\n",
        "    \"\"\"\n",
        "    Végső eredmények validálása és részletes statisztikák.\n",
        "    \"\"\"\n",
        "    \n",
        "    logger.info(\"Eredmények validálása és végső statisztikák...\")\n",
        "    \n",
        "    try:\n",
        "        # Parquet fájl betöltése validáláshoz\n",
        "        logger.info(f\"Validációs betöltés: {OUTPUT_PARQUET}\")\n",
        "        validation_df = pd.read_parquet(OUTPUT_PARQUET)\n",
        "        \n",
        "        # Alapvető statisztikák\n",
        "        total_rows = len(validation_df)\n",
        "        logger.info(f\"Betöltött sorok: {total_rows:,}\")\n",
        "        \n",
        "        # Embedding validáció\n",
        "        embedding_stats = {\n",
        "            'total_embeddings': total_rows,\n",
        "            'non_null_embeddings': validation_df['embedding'].notna().sum(),\n",
        "            'correct_dimension': 0,\n",
        "            'nan_embeddings': 0,\n",
        "            'zero_embeddings': 0\n",
        "        }\n",
        "        \n",
        "        logger.info(\"Embedding validáció...\")\n",
        "        \n",
        "        for idx, emb in tqdm(enumerate(validation_df['embedding']), \n",
        "                           total=len(validation_df), \n",
        "                           desc=\"Validálás\"):\n",
        "            if emb is not None and isinstance(emb, list):\n",
        "                if len(emb) == 8192:\n",
        "                    embedding_stats['correct_dimension'] += 1\n",
        "                    \n",
        "                    # NaN és zero ellenőrzés\n",
        "                    emb_array = np.array(emb)\n",
        "                    if np.any(np.isnan(emb_array)):\n",
        "                        embedding_stats['nan_embeddings'] += 1\n",
        "                    elif np.all(emb_array == 0):\n",
        "                        embedding_stats['zero_embeddings'] += 1\n",
        "        \n",
        "        # Metadata validáció\n",
        "        metadata_stats = {\n",
        "            'total_metadata': validation_df['metadata_json'].notna().sum(),\n",
        "            'valid_json': 0,\n",
        "            'doc_ids_present': validation_df['doc_id'].notna().sum(),\n",
        "            'unique_doc_ids': validation_df['doc_id'].nunique()\n",
        "        }\n",
        "        \n",
        "        logger.info(\"Metadata validáció...\")\n",
        "        \n",
        "        for metadata_json in validation_df['metadata_json'].dropna():\n",
        "            try:\n",
        "                json.loads(metadata_json)\n",
        "                metadata_stats['valid_json'] += 1\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        # Jogterület és bíróság statisztikák\n",
        "        categorical_stats = {\n",
        "            'unique_birosagok': validation_df['birosag'].nunique() if 'birosag' in validation_df.columns else 0,\n",
        "            'unique_jogteruletek': validation_df['jogterulet'].nunique() if 'jogterulet' in validation_df.columns else 0\n",
        "        }\n",
        "        \n",
        "        if 'birosag' in validation_df.columns:\n",
        "            top_birosagok = validation_df['birosag'].value_counts().head(5)\n",
        "        \n",
        "        if 'jogterulet' in validation_df.columns:\n",
        "            top_jogteruletek = validation_df['jogterulet'].value_counts().head(5)\n",
        "        \n",
        "        # Eredmények megjelenítése\n",
        "        logger.info(\"\\nVÉGSŐ VALIDÁCIÓS EREDMÉNYEK\")\n",
        "        logger.info(\"=\" * 80)\n",
        "        \n",
        "        logger.info(\"ÁLTALÁNOS STATISZTIKÁK:\")\n",
        "        logger.info(f\"   Összes sor: {total_rows:,}\")\n",
        "        logger.info(f\"   Egyedi doc_id-k: {metadata_stats['unique_doc_ids']:,}\")\n",
        "        logger.info(f\"   Egyedi bíróságok: {categorical_stats['unique_birosagok']:,}\")\n",
        "        logger.info(f\"   Egyedi jogterületek: {categorical_stats['unique_jogteruletek']:,}\")\n",
        "        \n",
        "        logger.info(\"\\nEMBEDDING MINŐSÉG:\")\n",
        "        logger.info(f\"   Helyes dimenzió (8192): {embedding_stats['correct_dimension']:,}/{total_rows:,} \"\n",
        "                   f\"({embedding_stats['correct_dimension']/total_rows*100:.2f}%)\")\n",
        "        logger.info(f\"   NaN vektorok: {embedding_stats['nan_embeddings']:,}\")\n",
        "        logger.info(f\"   Nulla vektorok: {embedding_stats['zero_embeddings']:,}\")\n",
        "        \n",
        "        quality_score = (embedding_stats['correct_dimension'] - embedding_stats['nan_embeddings'] - \n",
        "                        embedding_stats['zero_embeddings']) / total_rows * 100\n",
        "        logger.info(f\"   Minőségi pontszám: {quality_score:.2f}%\")\n",
        "        \n",
        "        logger.info(\"\\nMETADATA MINŐSÉG:\")\n",
        "        logger.info(f\"   Érvényes JSON: {metadata_stats['valid_json']:,}/{metadata_stats['total_metadata']:,} \"\n",
        "                   f\"({metadata_stats['valid_json']/metadata_stats['total_metadata']*100:.2f}%)\")\n",
        "        \n",
        "        if 'birosag' in validation_df.columns:\n",
        "            logger.info(\"\\nTOP 5 BÍRÓSÁG:\")\n",
        "            for birosag, count in top_birosagok.items():\n",
        "                logger.info(f\"   • {birosag}: {count:,} dokumentum\")\n",
        "        \n",
        "        if 'jogterulet' in validation_df.columns:\n",
        "            logger.info(\"\\nTOP 5 JOGTERÜLET:\")\n",
        "            for jogterulet, count in top_jogteruletek.items():\n",
        "                logger.info(f\"   • {jogterulet}: {count:,} dokumentum\")\n",
        "        \n",
        "        logger.info(\"\\nTELJESÍTMÉNY ÖSSZEFOGLALÓ:\")\n",
        "        if 'results' in globals():\n",
        "            logger.info(f\"   Teljes futásidő: {results['total_time_hours']:.2f} óra\")\n",
        "            logger.info(f\"   Átlag sebesség: {results['average_speed']:.1f} sor/sec\")\n",
        "            logger.info(f\"   Feldolgozott chunk-ok: {results['chunk_count']}\")\n",
        "            logger.info(f\"   Csúcs memória: {results['embedding_stats']['peak_memory_gb']:.1f}GB\")\n",
        "        \n",
        "        logger.info(\"\\nKOMPATIBILITÁS ELLENŐRZÉS:\")\n",
        "        faiss_compatible = embedding_stats['correct_dimension'] == total_rows\n",
        "        graph_compatible = 'doc_id' in validation_df.columns and metadata_stats['doc_ids_present'] > 0\n",
        "        \n",
        "        logger.info(f\"   FAISS index kompatibilis: {'IGEN' if faiss_compatible else 'NEM'}\")\n",
        "        logger.info(f\"   Gráf builder kompatibilis: {'IGEN' if graph_compatible else 'NEM'}\")\n",
        "        logger.info(f\"   Downstream pipeline ready: {'IGEN' if faiss_compatible and graph_compatible else 'NEM'}\")\n",
        "        \n",
        "        logger.info(\"=\" * 80)\n",
        "        \n",
        "        # Fájl méret információ\n",
        "        file_size = os.path.getsize(OUTPUT_PARQUET) / (1024**3)\n",
        "        logger.info(f\"Kimeneti fájl mérete: {file_size:.2f} GB\")\n",
        "        \n",
        "        return {\n",
        "            'validation_successful': True,\n",
        "            'total_rows': total_rows,\n",
        "            'embedding_stats': embedding_stats,\n",
        "            'metadata_stats': metadata_stats,\n",
        "            'categorical_stats': categorical_stats,\n",
        "            'quality_score': quality_score,\n",
        "            'faiss_compatible': faiss_compatible,\n",
        "            'graph_compatible': graph_compatible,\n",
        "            'file_size_gb': file_size\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Validációs hiba: {e}\")\n",
        "        return {'validation_successful': False, 'error': str(e)}\n",
        "\n",
        "# Validáció futtatása\n",
        "logger.info(\"Végső validáció indítása...\")\n",
        "validation_results = validate_and_finalize_results()\n",
        "\n",
        "if validation_results['validation_successful']:\n",
        "    print(\"\\nOPTIMALIZÁLT QWEN3-8B EMBEDDING GENERÁLÁS SIKERESEN BEFEJEZVE!\")\n",
        "    print(f\"Minőségi pontszám: {validation_results['quality_score']:.2f}%\")\n",
        "    print(f\"Fájl méret: {validation_results['file_size_gb']:.2f} GB\")\n",
        "    print(f\"FAISS kompatibilis: {'IGEN' if validation_results['faiss_compatible'] else 'NEM'}\")\n",
        "    print(f\"Gráf kompatibilis: {'IGEN' if validation_results['graph_compatible'] else 'NEM'}\")\n",
        "else:\n",
        "    print(f\"Validáció sikertelen: {validation_results.get('error', 'Ismeretlen hiba')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#@title Eredmények Validálása és Végső Statisztikák\n",
        "def validate_and_finalize_results():\n",
        "    \"\"\"\n",
        "    Végső eredmények validálása és részletes statisztikák.\n",
        "    \"\"\"\n",
        "    \n",
        "    logger.info(\"Eredmények validálása és végső statisztikák...\")\n",
        "    \n",
        "    try:\n",
        "        # Parquet fájl betöltése validáláshoz\n",
        "        logger.info(f\"Validációs betöltés: {OUTPUT_PARQUET}\")\n",
        "        validation_df = pd.read_parquet(OUTPUT_PARQUET)\n",
        "        \n",
        "        # Alapvető statisztikák\n",
        "        total_rows = len(validation_df)\n",
        "        logger.info(f\"Betöltött sorok: {total_rows:,}\")\n",
        "        \n",
        "        # Embedding validáció\n",
        "        embedding_stats = {\n",
        "            'total_embeddings': total_rows,\n",
        "            'non_null_embeddings': validation_df['embedding'].notna().sum(),\n",
        "            'correct_dimension': 0,\n",
        "            'nan_embeddings': 0,\n",
        "            'zero_embeddings': 0\n",
        "        }\n",
        "        \n",
        "        logger.info(\"Embedding validáció...\")\n",
        "        \n",
        "        for idx, emb in tqdm(enumerate(validation_df['embedding']), \n",
        "                           total=len(validation_df), \n",
        "                           desc=\"Validálás\"):\n",
        "            if emb is not None and isinstance(emb, list):\n",
        "                if len(emb) == 8192:\n",
        "                    embedding_stats['correct_dimension'] += 1\n",
        "                    \n",
        "                    # NaN és zero ellenőrzés\n",
        "                    emb_array = np.array(emb)\n",
        "                    if np.any(np.isnan(emb_array)):\n",
        "                        embedding_stats['nan_embeddings'] += 1\n",
        "                    elif np.all(emb_array == 0):\n",
        "                        embedding_stats['zero_embeddings'] += 1\n",
        "        \n",
        "        # Metadata validáció\n",
        "        metadata_stats = {\n",
        "            'total_metadata': validation_df['metadata_json'].notna().sum(),\n",
        "            'valid_json': 0,\n",
        "            'doc_ids_present': validation_df['doc_id'].notna().sum(),\n",
        "            'unique_doc_ids': validation_df['doc_id'].nunique()\n",
        "        }\n",
        "        \n",
        "        logger.info(\"Metadata validáció...\")\n",
        "        \n",
        "        for metadata_json in validation_df['metadata_json'].dropna():\n",
        "            try:\n",
        "                json.loads(metadata_json)\n",
        "                metadata_stats['valid_json'] += 1\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        # Jogterület és bíróság statisztikák\n",
        "        categorical_stats = {\n",
        "            'unique_birosagok': validation_df['birosag'].nunique() if 'birosag' in validation_df.columns else 0,\n",
        "            'unique_jogteruletek': validation_df['jogterulet'].nunique() if 'jogterulet' in validation_df.columns else 0\n",
        "        }\n",
        "        \n",
        "        if 'birosag' in validation_df.columns:\n",
        "            top_birosagok = validation_df['birosag'].value_counts().head(5)\n",
        "        \n",
        "        if 'jogterulet' in validation_df.columns:\n",
        "            top_jogteruletek = validation_df['jogterulet'].value_counts().head(5)\n",
        "        \n",
        "        # Eredmények megjelenítése\n",
        "        logger.info(\"\\nVÉGSŐ VALIDÁCIÓS EREDMÉNYEK\")\n",
        "        logger.info(\"=\" * 80)\n",
        "        \n",
        "        logger.info(\"ÁLTALÁNOS STATISZTIKÁK:\")\n",
        "        logger.info(f\"   Összes sor: {total_rows:,}\")\n",
        "        logger.info(f\"   Egyedi doc_id-k: {metadata_stats['unique_doc_ids']:,}\")\n",
        "        logger.info(f\"   Egyedi bíróságok: {categorical_stats['unique_birosagok']:,}\")\n",
        "        logger.info(f\"   Egyedi jogterületek: {categorical_stats['unique_jogteruletek']:,}\")\n",
        "        \n",
        "        logger.info(\"\\nEMBEDDING MINŐSÉG:\")\n",
        "        logger.info(f\"   Helyes dimenzió (8192): {embedding_stats['correct_dimension']:,}/{total_rows:,} \"\n",
        "                   f\"({embedding_stats['correct_dimension']/total_rows*100:.2f}%)\")\n",
        "        logger.info(f\"   NaN vektorok: {embedding_stats['nan_embeddings']:,}\")\n",
        "        logger.info(f\"   Nulla vektorok: {embedding_stats['zero_embeddings']:,}\")\n",
        "        \n",
        "        quality_score = (embedding_stats['correct_dimension'] - embedding_stats['nan_embeddings'] - \n",
        "                        embedding_stats['zero_embeddings']) / total_rows * 100\n",
        "        logger.info(f\"   Minőségi pontszám: {quality_score:.2f}%\")\n",
        "        \n",
        "        logger.info(\"\\nMETADATA MINŐSÉG:\")\n",
        "        logger.info(f\"   Érvényes JSON: {metadata_stats['valid_json']:,}/{metadata_stats['total_metadata']:,} \"\n",
        "                   f\"({metadata_stats['valid_json']/metadata_stats['total_metadata']*100:.2f}%)\")\n",
        "        \n",
        "        if 'birosag' in validation_df.columns:\n",
        "            logger.info(\"\\nTOP 5 BÍRÓSÁG:\")\n",
        "            for birosag, count in top_birosagok.items():\n",
        "                logger.info(f\"   • {birosag}: {count:,} dokumentum\")\n",
        "        \n",
        "        if 'jogterulet' in validation_df.columns:\n",
        "            logger.info(\"\\nTOP 5 JOGTERÜLET:\")\n",
        "            for jogterulet, count in top_jogteruletek.items():\n",
        "                logger.info(f\"   • {jogterulet}: {count:,} dokumentum\")\n",
        "        \n",
        "        logger.info(\"\\nTELJESÍTMÉNY ÖSSZEFOGLALÓ:\")\n",
        "        if 'results' in globals():\n",
        "            logger.info(f\"   Teljes futásidő: {results['total_time_hours']:.2f} óra\")\n",
        "            logger.info(f\"   Átlag sebesség: {results['average_speed']:.1f} sor/sec\")\n",
        "            logger.info(f\"   Feldolgozott chunk-ok: {results['chunk_count']}\")\n",
        "            logger.info(f\"   Csúcs memória: {results['embedding_stats']['peak_memory_gb']:.1f}GB\")\n",
        "        \n",
        "        logger.info(\"\\nKOMPATIBILITÁS ELLENŐRZÉS:\")\n",
        "        faiss_compatible = embedding_stats['correct_dimension'] == total_rows\n",
        "        graph_compatible = 'doc_id' in validation_df.columns and metadata_stats['doc_ids_present'] > 0\n",
        "        \n",
        "        logger.info(f\"   FAISS index kompatibilis: {'IGEN' if faiss_compatible else 'NEM'}\")\n",
        "        logger.info(f\"   Gráf builder kompatibilis: {'IGEN' if graph_compatible else 'NEM'}\")\n",
        "        logger.info(f\"   Downstream pipeline ready: {'IGEN' if faiss_compatible and graph_compatible else 'NEM'}\")\n",
        "        \n",
        "        logger.info(\"=\" * 80)\n",
        "        \n",
        "        # Fájl méret információ\n",
        "        file_size = os.path.getsize(OUTPUT_PARQUET) / (1024**3)\n",
        "        logger.info(f\"Kimeneti fájl mérete: {file_size:.2f} GB\")\n",
        "        \n",
        "        return {\n",
        "            'validation_successful': True,\n",
        "            'total_rows': total_rows,\n",
        "            'embedding_stats': embedding_stats,\n",
        "            'metadata_stats': metadata_stats,\n",
        "            'categorical_stats': categorical_stats,\n",
        "            'quality_score': quality_score,\n",
        "            'faiss_compatible': faiss_compatible,\n",
        "            'graph_compatible': graph_compatible,\n",
        "            'file_size_gb': file_size\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Validációs hiba: {e}\")\n",
        "        return {'validation_successful': False, 'error': str(e)}\n",
        "\n",
        "# Validáció futtatása\n",
        "logger.info(\"Végső validáció indítása...\")\n",
        "validation_results = validate_and_finalize_results()\n",
        "\n",
        "if validation_results['validation_successful']:\n",
        "    print(\"\\nOPTIMALIZÁLT QWEN3-8B EMBEDDING GENERÁLÁS SIKERESEN BEFEJEZVE!\")\n",
        "    print(f\"Minőségi pontszám: {validation_results['quality_score']:.2f}%\")\n",
        "    print(f\"Fájl méret: {validation_results['file_size_gb']:.2f} GB\")\n",
        "    print(f\"FAISS kompatibilis: {'IGEN' if validation_results['faiss_compatible'] else 'NEM'}\")\n",
        "    print(f\"Gráf kompatibilis: {'IGEN' if validation_results['graph_compatible'] else 'NEM'}\")\n",
        "else:\n",
        "    print(f\"Validáció sikertelen: {validation_results.get('error', 'Ismeretlen hiba')}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
