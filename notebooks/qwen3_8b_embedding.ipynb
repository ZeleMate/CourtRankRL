{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 1. KÖRNYEZET BEÁLLÍTÁSA ===\n",
        "# Könyvtárak telepítése és importálása\n",
        "%pip install -U torch sentence-transformers accelerate pyarrow pandas tqdm transformers runpod python-dotenv\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import json\n",
        "import pyarrow.parquet as pq\n",
        "import torch\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List\n",
        "from pathlib import Path\n",
        "import os\n",
        "import runpod\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# .env fájl betöltése a RUNPOD_API_KEY betöltéséhez\n",
        "load_dotenv()\n",
        "\n",
        "# GPU-specifikus optimalizációk már nem szükségesek, mivel a számítás a felhőben történik\n",
        "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "# torch.backends.cudnn.benchmark = True\n",
        "# torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "print(f\"CUDA elérhető lokálisan: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 2. KONFIGURÁCIÓ ===\n",
        "# RunPod Serverless API-hoz igazított konfiguráció.\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# API kulcs és Endpoint ID beolvasása\n",
        "RUNPOD_API_KEY = os.getenv(\"RUNPOD_API_KEY\")\n",
        "RUNPOD_ENDPOINT_ID = \"5hjxb1eht972gw\" # A RunPod UI-ból kimásolt endpoint ID\n",
        "\n",
        "if not RUNPOD_API_KEY:\n",
        "    raise ValueError(\"A RUNPOD_API_KEY környezeti változó nincs beállítva! Állítsd be egy .env fájlban.\")\n",
        "\n",
        "# Bemeneti és kimeneti fájlok\n",
        "INPUT_CSV_PATH = Path(\"../processed_data/cleaned_data_for_embedding.csv\")\n",
        "OUTPUT_PARQUET_PATH = Path(\"../processed_data/documents_with_embeddings_api.parquet\")\n",
        "\n",
        "# Embedding és batch méret beállítások\n",
        "EMBEDDING_DIMENSION = 1024\n",
        "# Kliens oldali batch méret, egy kérésben ennyi szöveg megy el az API-nak\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "print(f\"RunPod Endpoint ID: {RUNPOD_ENDPOINT_ID}\")\n",
        "print(f\"Input: {INPUT_CSV_PATH}\")\n",
        "print(f\"Output: {OUTPUT_PARQUET_PATH}\")\n",
        "print(f\"Batch méret: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 3. EMBEDDING GENERÁTOR OSZTÁLY (RUNPOD API) ===\n",
        "class EmbeddingGeneratorAPI:\n",
        "    def __init__(self, api_key: str, endpoint_id: str, batch_size: int, dimension: int):\n",
        "        self.api_key = api_key\n",
        "        self.endpoint_id = endpoint_id\n",
        "        self.batch_size = batch_size\n",
        "        self.dimension = dimension\n",
        "        runpod.api_key = self.api_key\n",
        "        self.endpoint = runpod.Endpoint(self.endpoint_id)\n",
        "        print(f\"RunPod API generátor inicializálva a(z) '{self.endpoint_id}' endpoint-ra.\")\n",
        "\n",
        "    def load_model(self):\n",
        "        # Nincs szükség modell betöltésére, az endpoint kezeli.\n",
        "        # Ez a metódus a kompatibilitás miatt marad.\n",
        "        print(\"A modell a RunPod szerveren fut, nincs szükség lokális betöltésre.\")\n",
        "\n",
        "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
        "        all_embeddings = []\n",
        "        \n",
        "        # Feldolgozás batch-ekben\n",
        "        for i in tqdm(range(0, len(texts), self.batch_size), desc=\"Embedding generálás (API)\"):\n",
        "            batch_texts = texts[i:i + self.batch_size]\n",
        "            \n",
        "            request = {\n",
        "                \"input\": {\n",
        "                    \"texts\": batch_texts,\n",
        "                    \"normalize_embeddings\": True\n",
        "                }\n",
        "            }\n",
        "            \n",
        "            try:\n",
        "                # Szinkron kérés küldése, ami megvárja a választ\n",
        "                result = self.endpoint.run_sync(request, timeout=600) # 10 perc timeout\n",
        "                batch_embeddings = result['output']['embeddings']\n",
        "                all_embeddings.extend(batch_embeddings)\n",
        "            except Exception as e:\n",
        "                print(f\"Hiba a RunPod API hívás során a(z) {i}-edik elemnél: {e}\")\n",
        "                # Hibakezelés: üres embeddingekkel töltjük fel a hibás batch helyét\n",
        "                error_placeholder = np.zeros((len(batch_texts), self.dimension), dtype=np.float32)\n",
        "                all_embeddings.extend(error_placeholder.tolist())\n",
        "                continue\n",
        "        \n",
        "        embeddings_array = np.array(all_embeddings, dtype=np.float32)\n",
        "\n",
        "        # Biztonsági ellenőrzés a dimenzióra\n",
        "        if embeddings_array.shape[1] != self.dimension:\n",
        "             print(f\"Figyelmeztetés: Váratlan embedding dimenzió: {embeddings_array.shape[1]}. Korrekció {self.dimension}-ra.\")\n",
        "             # Itt vagy hibát dobunk, vagy megpróbáljuk korrigálni, ha lehetséges\n",
        "             # Most feltételezzük, hogy ez egy kritikus hiba\n",
        "             raise ValueError(f\"Váratlan embedding dimenzió: {embeddings_array.shape[1]}\")\n",
        "            \n",
        "        return embeddings_array\n",
        "\n",
        "    def _cleanup_memory(self):\n",
        "        # Nincs szükség GPU memória takarítására\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 4. FŐ FELDOLGOZÁSI FOLYAMAT ===\n",
        "def create_metadata_json(row: pd.Series) -> str:\n",
        "    \"\"\"Létrehoz egy JSON stringet a sor metaadataiból.\"\"\"\n",
        "    metadata_cols = [col for col in row.index if col not in ['text', 'embedding']]\n",
        "    metadata_dict = row[metadata_cols].dropna().to_dict()\n",
        "    return json.dumps({k: str(v) for k, v in metadata_dict.items()}, ensure_ascii=False)\n",
        "\n",
        "def main():\n",
        "    print(\"Feldolgozás indítása a RunPod API-val...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Bemeneti adatok beolvasása\n",
        "    if not INPUT_CSV_PATH.exists():\n",
        "        raise FileNotFoundError(f\"Hiba: A bemeneti fájl nem található: {INPUT_CSV_PATH}\")\n",
        "    \n",
        "    print(f\"Bemeneti CSV beolvasása: {INPUT_CSV_PATH}\")\n",
        "    # Egyszerűsített beolvasás, a C motor használatával\n",
        "    df = pd.read_csv(INPUT_CSV_PATH)\n",
        "    print(f\"{len(df):,} sor sikeresen beolvasva.\")\n",
        "\n",
        "    # Szövegek kinyerése\n",
        "    df['text'] = df['text'].fillna('')\n",
        "    texts_to_process = df['text'].astype(str).tolist()\n",
        "    \n",
        "    if not texts_to_process:\n",
        "        print(\"Nincs feldolgozandó szöveg a bemeneti fájlban.\")\n",
        "        return\n",
        "\n",
        "    # Embedding generátor inicializálása és \"modell betöltése\"\n",
        "    generator = EmbeddingGeneratorAPI(RUNPOD_API_KEY, RUNPOD_ENDPOINT_ID, BATCH_SIZE, EMBEDDING_DIMENSION)\n",
        "    generator.load_model() # Kompatibilitási hívás, valójában nem csinál semmit\n",
        "\n",
        "    # Embedding generálás a teljes adathalmazon\n",
        "    print(\"Embedding generálás megkezdése a RunPod API-n keresztül...\")\n",
        "    embeddings = generator.generate_embeddings(texts_to_process)\n",
        "    \n",
        "    # Memória takarítás a nagy művelet után\n",
        "    generator._cleanup_memory()\n",
        "\n",
        "    # Eredmények hozzáadása a DataFrame-hez\n",
        "    if len(embeddings) == len(df):\n",
        "        df['embedding'] = list(embeddings)\n",
        "    else:\n",
        "        print(f\"KRITIKUS HIBA: Az embeddingek száma ({len(embeddings)}) nem egyezik a DataFrame sorainak számával ({len(df)}). A program leáll.\")\n",
        "        return\n",
        "\n",
        "    # Metaadatok generálása\n",
        "    print(\"Metaadat JSON generálása...\")\n",
        "    df['metadata_json'] = [create_metadata_json(row) for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Metaadat JSON\")]\n",
        "\n",
        "    # Kimeneti DataFrame és mentés Parquet formátumba\n",
        "    final_df = df[['doc_id', 'text', 'embedding', 'metadata_json']]\n",
        "    OUTPUT_PARQUET_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Eredmények mentése a Parquet fájlba: {OUTPUT_PARQUET_PATH}\")\n",
        "    final_df.to_parquet(OUTPUT_PARQUET_PATH, index=False, compression='snappy')\n",
        "    \n",
        "    # Összegzés\n",
        "    total_rows_processed = len(final_df)\n",
        "    total_time_seconds = time.time() - start_time\n",
        "    rows_per_second = total_rows_processed / total_time_seconds if total_time_seconds > 0 else 0\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"✅ FELDOLGOZÁS BEFEJEZVE\")\n",
        "    print(f\"📄 Kimeneti fájl: {OUTPUT_PARQUET_PATH}\")\n",
        "    print(f\"⏱️ Teljes idő: {total_time_seconds:.2f} másodperc ({total_time_seconds / 60:.2f} perc)\")\n",
        "    print(f\"📊 Feldolgozott sorok: {total_rows_processed:,}\")\n",
        "    print(f\"⚡ Átlagos sebesség: {rows_per_second:.2f} sor/mp\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# Fő folyamat futtatása\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 5. VALIDÁCIÓ ===\n",
        "print(\"Kimeneti Parquet fájl validálása...\")\n",
        "\n",
        "if OUTPUT_PARQUET_PATH.exists():\n",
        "    try:\n",
        "        parquet_file = pq.ParquetFile(OUTPUT_PARQUET_PATH)\n",
        "        file_num_rows = parquet_file.metadata.num_rows\n",
        "        file_size_mb = OUTPUT_PARQUET_PATH.stat().st_size / (1024 * 1024)\n",
        "        \n",
        "        df_sample = pd.read_parquet(OUTPUT_PARQUET_PATH, engine='pyarrow').head(5)\n",
        "        sample_embedding = df_sample['embedding'].iloc[0]\n",
        "        \n",
        "        print(\"\\n✅ VALIDÁCIÓ SIKERES!\")\n",
        "        print(f\"  Fájl méret: {file_size_mb:.2f} MB\")\n",
        "        print(f\"  Sorok száma: {file_num_rows:,}\")\n",
        "        print(f\"  Oszlopok: {df_sample.columns.tolist()}\")\n",
        "        print(f\"  Első embedding dimenziója: {len(sample_embedding)}\")\n",
        "        print(\"\\n--- Minta Adatsor ---\")\n",
        "        display(df_sample)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Hiba a Parquet fájl validálása közben: {e}\")\n",
        "        print(f\"\\n❌ HIBA a validáció során: {e}\")\n",
        "else:\n",
        "    print(\"A kimeneti Parquet fájl nem jött létre.\")\n",
        "    print(\"\\n❌ HIBA: A kimeneti fájl nem található!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "courtrankrl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
