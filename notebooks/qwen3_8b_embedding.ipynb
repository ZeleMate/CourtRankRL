{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 1. K√ñRNYEZET BE√ÅLL√çT√ÅSA ===\n",
        "# K√∂nyvt√°rak telep√≠t√©se √©s import√°l√°sa\n",
        "%pip install -U torch sentence-transformers accelerate pyarrow pandas tqdm transformers\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import json\n",
        "import pyarrow.parquet as pq\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# A PyTorch rugalmasabban kezelje a GPU mem√≥ri√°t.\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# GPU optimaliz√°ci√≥ A100-hoz\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "print(f\"CUDA el√©rhet≈ë: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 2. KONFIGUR√ÅCI√ì ===\n",
        "# RunPod A100 felh≈ë k√∂rnyezethez igaz√≠tott konfigur√°ci√≥.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Bemeneti √©s kimeneti f√°jlok\n",
        "# Gy≈ëz≈ëdj meg r√≥la, hogy a f√°jlok a megfelel≈ë helyen vannak a felh≈ë k√∂rnyezetben!\n",
        "INPUT_CSV_PATH = Path(\"/workspace/cleaned_data_for_embedding.csv\")\n",
        "OUTPUT_PARQUET_PATH = Path(\"/workspace/documents_with_embeddings.parquet\")\n",
        "\n",
        "# Modell √©s batch m√©ret be√°ll√≠t√°sok\n",
        "MODEL_NAME = \"Qwen/Qwen3-Embedding-0.6B\"\n",
        "EMBEDDING_DIMENSION = 1024\n",
        "# A100 k√°rty√°n egy nagyobb batch m√©ret is hat√©kony lehet\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "print(f\"Input: {INPUT_CSV_PATH}\")\n",
        "print(f\"Output: {OUTPUT_PARQUET_PATH}\")\n",
        "print(f\"Modell: {MODEL_NAME}\")\n",
        "print(f\"Batch m√©ret: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 3. EMBEDDING GENER√ÅTOR OSZT√ÅLY ===\n",
        "class EmbeddingGenerator:\n",
        "    def __init__(self, model_name: str, batch_size: int, dimension: int, device: str = 'cuda'):\n",
        "        self.model_name = model_name\n",
        "        self.batch_size = batch_size\n",
        "        self.dimension = dimension\n",
        "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
        "        self.model = None\n",
        "        print(f\"Gener√°tor inicializ√°lva a(z) '{self.device}' eszk√∂z√∂n.\")\n",
        "\n",
        "    def load_model(self):\n",
        "        if self.model is not None:\n",
        "            print(\"Modell m√°r be van t√∂ltve.\")\n",
        "            return\n",
        "        try:\n",
        "            print(f\"'{self.model_name}' modell bet√∂lt√©se...\")\n",
        "            self.model = SentenceTransformer(self.model_name, device=self.device, trust_remote_code=True)\n",
        "            self._warmup_model()\n",
        "            print(\"Modell sikeresen bet√∂ltve √©s bemeleg√≠tve.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Modell bet√∂lt√©si hiba: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _warmup_model(self):\n",
        "        print(\"Modell bemeleg√≠t√©se...\")\n",
        "        # Egy r√∂vid sz√∂veggel \"bemeleg√≠tj√ºk\" a modellt\n",
        "        self.generate_embeddings([\"meleg√≠t√©s\"])\n",
        "        self._cleanup_memory()\n",
        "        print(\"Bemeleg√≠t√©s k√©sz.\")\n",
        "\n",
        "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"A modell nincs bet√∂ltve. H√≠vd meg a load_model() met√≥dust.\")\n",
        "        \n",
        "        embeddings = self.model.encode(\n",
        "            texts, \n",
        "            batch_size=self.batch_size, \n",
        "            normalize_embeddings=True, \n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "        \n",
        "        # Biztons√°gi ellen≈ërz√©s a dimenzi√≥ra\n",
        "        if embeddings.shape[1] != self.dimension:\n",
        "            print(f\"Figyelmeztet√©s: V√°ratlan embedding dimenzi√≥: {embeddings.shape[1]}. Korrekci√≥ {self.dimension}-ra.\")\n",
        "            embeddings = embeddings[:, :self.dimension]\n",
        "            \n",
        "        return embeddings.astype(np.float32)\n",
        "\n",
        "    def _cleanup_memory(self):\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 4. F≈ê FELDOLGOZ√ÅSI FOLYAMAT ===\n",
        "def create_metadata_json(row: pd.Series) -> str:\n",
        "    \"\"\"L√©trehoz egy JSON stringet a sor metaadataib√≥l.\"\"\"\n",
        "    metadata_cols = [col for col in row.index if col not in ['text', 'embedding']]\n",
        "    metadata_dict = row[metadata_cols].dropna().to_dict()\n",
        "    return json.dumps({k: str(v) for k, v in metadata_dict.items()}, ensure_ascii=False)\n",
        "\n",
        "def main():\n",
        "    print(\"Feldolgoz√°s ind√≠t√°sa...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Bemeneti adatok beolvas√°sa\n",
        "    if not INPUT_CSV_PATH.exists():\n",
        "        raise FileNotFoundError(f\"Hiba: A bemeneti f√°jl nem tal√°lhat√≥: {INPUT_CSV_PATH}\")\n",
        "    \n",
        "    print(f\"Bemeneti CSV beolvas√°sa: {INPUT_CSV_PATH}\")\n",
        "    # Egyszer≈±s√≠tett beolvas√°s, a C motor haszn√°lat√°val\n",
        "    df = pd.read_csv(INPUT_CSV_PATH)\n",
        "    print(f\"{len(df):,} sor sikeresen beolvasva.\")\n",
        "\n",
        "    # Sz√∂vegek kinyer√©se\n",
        "    df['text'] = df['text'].fillna('')\n",
        "    texts_to_process = df['text'].astype(str).tolist()\n",
        "    \n",
        "    if not texts_to_process:\n",
        "        print(\"Nincs feldolgozand√≥ sz√∂veg a bemeneti f√°jlban.\")\n",
        "        return\n",
        "\n",
        "    # Embedding gener√°tor inicializ√°l√°sa √©s modell bet√∂lt√©se\n",
        "    generator = EmbeddingGenerator(MODEL_NAME, BATCH_SIZE, EMBEDDING_DIMENSION)\n",
        "    generator.load_model()\n",
        "\n",
        "    # Embedding gener√°l√°s a teljes adathalmazon\n",
        "    print(\"Embedding gener√°l√°s megkezd√©se...\")\n",
        "    embeddings = generator.generate_embeddings(texts_to_process)\n",
        "    \n",
        "    # Mem√≥ria takar√≠t√°s a nagy m≈±velet ut√°n\n",
        "    generator._cleanup_memory()\n",
        "\n",
        "    # Eredm√©nyek hozz√°ad√°sa a DataFrame-hez\n",
        "    if len(embeddings) == len(df):\n",
        "        df['embedding'] = list(embeddings)\n",
        "    else:\n",
        "        print(f\"KRITIKUS HIBA: Az embeddingek sz√°ma ({len(embeddings)}) nem egyezik a DataFrame sorainak sz√°m√°val ({len(df)}). A program le√°ll.\")\n",
        "        return\n",
        "\n",
        "    # Metaadatok gener√°l√°sa\n",
        "    print(\"Metaadat JSON gener√°l√°sa...\")\n",
        "    df['metadata_json'] = [create_metadata_json(row) for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Metaadat JSON\")]\n",
        "\n",
        "    # Kimeneti DataFrame √©s ment√©s Parquet form√°tumba\n",
        "    final_df = df[['doc_id', 'text', 'embedding', 'metadata_json']]\n",
        "    OUTPUT_PARQUET_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Eredm√©nyek ment√©se a Parquet f√°jlba: {OUTPUT_PARQUET_PATH}\")\n",
        "    final_df.to_parquet(OUTPUT_PARQUET_PATH, index=False, compression='snappy')\n",
        "    \n",
        "    # √ñsszegz√©s\n",
        "    total_rows_processed = len(final_df)\n",
        "    total_time_seconds = time.time() - start_time\n",
        "    rows_per_second = total_rows_processed / total_time_seconds if total_time_seconds > 0 else 0\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"‚úÖ FELDOLGOZ√ÅS BEFEJEZVE\")\n",
        "    print(f\"üìÑ Kimeneti f√°jl: {OUTPUT_PARQUET_PATH}\")\n",
        "    print(f\"‚è±Ô∏è Teljes id≈ë: {total_time_seconds:.2f} m√°sodperc ({total_time_seconds / 60:.2f} perc)\")\n",
        "    print(f\"üìä Feldolgozott sorok: {total_rows_processed:,}\")\n",
        "    print(f\"‚ö° √Åtlagos sebess√©g: {rows_per_second:.2f} sor/mp\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# F≈ë folyamat futtat√°sa\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 5. VALID√ÅCI√ì ===\n",
        "print(\"Kimeneti Parquet f√°jl valid√°l√°sa...\")\n",
        "\n",
        "if OUTPUT_PARQUET_PATH.exists():\n",
        "    try:\n",
        "        parquet_file = pq.ParquetFile(OUTPUT_PARQUET_PATH)\n",
        "        file_num_rows = parquet_file.metadata.num_rows\n",
        "        file_size_mb = OUTPUT_PARQUET_PATH.stat().st_size / (1024 * 1024)\n",
        "        \n",
        "        df_sample = pd.read_parquet(OUTPUT_PARQUET_PATH, engine='pyarrow').head(5)\n",
        "        sample_embedding = df_sample['embedding'].iloc[0]\n",
        "        \n",
        "        print(\"\\n‚úÖ VALID√ÅCI√ì SIKERES!\")\n",
        "        print(f\"  F√°jl m√©ret: {file_size_mb:.2f} MB\")\n",
        "        print(f\"  Sorok sz√°ma: {file_num_rows:,}\")\n",
        "        print(f\"  Oszlopok: {df_sample.columns.tolist()}\")\n",
        "        print(f\"  Els≈ë embedding dimenzi√≥ja: {len(sample_embedding)}\")\n",
        "        print(\"\\n--- Minta Adatsor ---\")\n",
        "        display(df_sample)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Hiba a Parquet f√°jl valid√°l√°sa k√∂zben: {e}\")\n",
        "        print(f\"\\n‚ùå HIBA a valid√°ci√≥ sor√°n: {e}\")\n",
        "else:\n",
        "    print(\"A kimeneti Parquet f√°jl nem j√∂tt l√©tre.\")\n",
        "    print(\"\\n‚ùå HIBA: A kimeneti f√°jl nem tal√°lhat√≥!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
